<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Free online resources to study reinforcement learning and deep RL | Douglas Meneghetti </title> <meta name="author" content="Douglas De Rizzo Meneghetti"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://douglasrizzo.github.io/blog/2020/05/rl-resources/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Douglas Meneghetti </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Free online resources to study reinforcement learning and deep RL</h1> <p class="post-meta"> May 10, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/category/awesome-list"> <i class="fa-solid fa-tag fa-sm"></i> awesome-list</a>   <a href="/blog/category/reinforcement-learning"> <i class="fa-solid fa-tag fa-sm"></i> reinforcement-learning</a>   <a href="/blog/category/deep-reinforcement-learning"> <i class="fa-solid fa-tag fa-sm"></i> deep-reinforcement-learning</a>   <a href="/blog/category/self-study"> <i class="fa-solid fa-tag fa-sm"></i> self-study</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Over the last few years and months, I gathered some material that I used to study reinforcement learning and deep reinforcement learning, mostly by myself, as part of my PhD formation.</p> <p>I hope these links can help others as much as they’ve helped me. The list also serves the purpose of remembering me that this material exists, since memory loss is a thing during a PhD.</p> <ul> <li><a href="#books-and-surveys">Books and surveys</a></li> <li><a href="#courses">Courses</a></li> <li><a href="#miscellaneous-online-material">Miscellaneous online material</a></li> <li><a href="#algorithm-implementations">Algorithm implementations</a></li> </ul> <h2 id="books-and-surveys">Books and surveys</h2> <p>The current textbook for the area of reinforcement learning in general is</p> <blockquote> <p>R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction, 2nd ed. Cambridge, Mass: The MIT Press, 2018.</p> </blockquote> <p>It is freely and legally available <a href="http://www.incompleteideas.net/book/the-book.html" rel="external nofollow noopener" target="_blank">here</a> and you can find my name in <a href="http://www.incompleteideas.net/book/errata.html" rel="external nofollow noopener" target="_blank">the errata</a>.</p> <p>A textual reference for the overall area of deep RL is hard to pinpoint, but personally, I recommend the following survey:</p> <blockquote> <p>Y. Li, “Deep Reinforcement Learning, ” arXiv:1810.06339 [cs, stat], Oct. 2018, Accessed: May 08, 2020. [Online]. Available: http://arxiv.org/abs/1810.06339.</p> </blockquote> <h2 id="courses">Courses</h2> <ul> <li> <p><a href="https://www.coursera.org/specializations/reinforcement-learning" rel="external nofollow noopener" target="_blank">Reinforcement Learning Specialization on Coursera</a>: I believe that, as of now, this is the most educational and informative resource available online to learn the fundamentals of RL from scratch. It is ministered by Martha and David White from UAlberta with special appearances by many prominent researchers.</p> <p>While the specialization follows Sutton’s book, it also adds its own value by giving additional step-by-step examples and providing additional definitions or explanations of the definitions from the book. You also learn a lot from the quizzes and practical tests, which are done in Jupyter Notebooks. I definitely recommend this as a starting point for anyone who wants to dig deep into RL, as the specialization focuses on the foundations of the area.</p> <p>A disclaimer: the course is not actually free. You can watch all the lectures and work on all non-graded exercises, but all the graded ones (which are needed to get the certificate) are locked. You also need to pay for each one of the 4 certificates in order to finish the specialization. One option to circumvent this is to see if you are eligible for <a href="https://www.coursera.org/for-university-and-college-students" rel="external nofollow noopener" target="_blank">Coursera for university and students</a> (must have a <code class="language-plaintext highlighter-rouge">.edu</code> email) or for Financial Aid <a href="https://learner.coursera.help/hc/en-us/articles/209819033-Apply-for-Financial-Aid-or-a-Scholarship" rel="external nofollow noopener" target="_blank">[1]</a> <a href="https://blog.coursera.org/courseras-financial-aid-what-it-is-and-who-is/" rel="external nofollow noopener" target="_blank">[2]</a>. In the case of Financial Aid, you must ask it for each course in the specialization.</p> </li> <li> <p><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ" rel="external nofollow noopener" target="_blank">Introduction to reinforcement learning by David Silver</a>: Before the RL specialization, I believe this playlist was the go-to reference to study RL. David Silver is also a contemporary reference in the area and his lectures also use Sutton’s book as reference. My only grudge with the course is that it assumes considerable previous knowledge in many areas, at times sounding more like a graduate course e.g, by encouraging students to prove statements while skipping $k$-armed bandits, for example. <a href="https://www.davidsilver.uk/teaching/" rel="external nofollow noopener" target="_blank">Slides available</a>.</p> </li> <li> <p><a href="https://www.youtube.com/playlist?list=PLsuq9stvuZe4pc8T4NutncqaYzpmwBJtg" rel="external nofollow noopener" target="_blank">Deep RL Bootcamp</a>: lectures with some of the scientists behind the groundbreaking DRL algorithms created in the last years. Good explanations of DQN and policy gradient methods from their creators. <a href="https://sites.google.com/view/deep-rl-bootcamp/lectures" rel="external nofollow noopener" target="_blank">Slides available</a>.</p> </li> <li> <p><a href="http://rail.eecs.berkeley.edu/deeprlcourse/" rel="external nofollow noopener" target="_blank">CS 285 at UC Berkeley</a>: a full DRL course. This looks like the real deal. Unfortunately, it was not the material I used to learn what I know, but people highly recommend it, so I’ll keep it in the list.</p> </li> <li> <p><a href="https://github.com/yandexdataschool/Practical_RL" rel="external nofollow noopener" target="_blank">Practical_RL</a>: <em>An open course on reinforcement learning in the wild […] maintained to be friendly to online students (both english and russian).</em> This one is mostly maintained on GitHub. Unfortunately, lectures are in Russian, but there are slides and links to more material.</p> </li> <li> <p><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZBKeNJ-JE_eyJHZ7XgBoAyb" rel="external nofollow noopener" target="_blank">Reinforcement Learning Course | DeepMind &amp; UCL</a>: A YouTube playlist with 10 lectures averaging 1h40min each lecture</p> </li> </ul> <h2 id="miscellaneous-online-material">Miscellaneous online material</h2> <ul> <li> <p><a href="https://spinningup.openai.com/" rel="external nofollow noopener" target="_blank">Spinning Up in Deep RL</a>: <em>an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning.</em> The website has great summaries about the policy gradient algorithms created by OpenAI, as well as references to the original papers.</p> </li> <li> <p>Arthur Juliani’s <a href="https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149" rel="external nofollow noopener" target="_blank">Simple Reinforcement learning series</a>.</p> </li> </ul> <h2 id="algorithm-implementations">Algorithm implementations</h2> <ul> <li> <p><a href="https://github.com/douglasrizzo/machine_learning/blob/master/include/GridWorld.hpp" rel="external nofollow noopener" target="_blank">My personal repository</a> where I have implemented policy iteration, value iteration, Monte Carlo ES, Sarsa and Q-Learning in C++ and applied it in a grid world.</p> </li> <li> <p>MorvanZhou’s simple and educational <a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/" rel="external nofollow noopener" target="_blank">Python implementations of classical RL algorithms</a>. I used them on a personal project and compiled them into a single, <a href="https://douglasrizzo.com.br/sc2qsr/rl.html" rel="external nofollow noopener" target="_blank">documented</a> Python module available <a href="https://github.com/douglasrizzo/sc2qsr/blob/master/sc2qsr/rl.py" rel="external nofollow noopener" target="_blank">here</a> under the same license.</p> </li> <li> <p>Implementations of model-free and policy gradient methods in PyTorch 0.4, in a very instructive way:</p> <ul> <li><a href="https://github.com/higgsfield/RL-Adventure" rel="external nofollow noopener" target="_blank">higgsfield/RL-Adventure</a></li> <li><a href="https://github.com/higgsfield/RL-Adventure-2" rel="external nofollow noopener" target="_blank">higgsfield/RL-Adventure-2</a></li> </ul> </li> <li> <p><a href="https://github.com/openai/baselines" rel="external nofollow noopener" target="_blank">OpenAI baselines</a>: Baseline implementations of most famous DRL algorithms by OpenAI (since the ones they found online were riddled with bugs).</p> </li> <li> <p><a href="https://github.com/hill-a/stable-baselines" rel="external nofollow noopener" target="_blank">Stable baselines</a>: a repository that is maintained more frequently than OpenAI’s. Their code is PEP8 compliant and actually documented.</p> </li> <li> <p>Arthur Juliani also has complete implementations over at his GitHub, as well as commented ones in his <a href="https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149" rel="external nofollow noopener" target="_blank">aforementioned series</a>.</p> </li> <li> <p>Denny Britz has <a href="https://github.com/dennybritz/reinforcement-learning" rel="external nofollow noopener" target="_blank">a very famous repository</a> of reinforcement algorithms over at GitHub.</p> </li> <li> <p><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html" rel="external nofollow noopener" target="_blank">PyTorch official DQN tutorial</a>: this is the intermediate step in the PyTorch tutorials so, if you fancy learning some PyTorch, I believe this is the most straightforward way to implement and debug your first DRL algorithm.</p> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/06/mathematics-self-study/">Resources to self-study mathematics for machine learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/03/local-gemma-chatbot-langchain-ollama/">Running a Gemma-powered question-answering chatbot locally with LangChain + Ollama</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/02/llm-qa-obsidian-rag/">Answering questions from an Obsidian database with LLMs + RAG</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/07/ts-queue-experiments/">Using task-spooler to queue experiments on Linux</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/05/cpp-structs-classes/">In C++, classes and structs are the same thing</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Douglas De Rizzo Meneghetti. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>