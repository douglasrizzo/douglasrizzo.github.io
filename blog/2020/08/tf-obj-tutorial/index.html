<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> How to train your own object detection models using the TensorFlow Object Detection API (2020 Update) | Douglas Meneghetti </title> <meta name="author" content="Douglas De Rizzo Meneghetti"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://douglasrizzo.github.io/blog/2020/08/tf-obj-tutorial/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Douglas Meneghetti </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">How to train your own object detection models using the TensorFlow Object Detection API (2020 Update)</h1> <p class="post-meta"> August 08, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> tensorflow</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> python</a>   <a href="/blog/tag/object-detection"> <i class="fa-solid fa-hashtag fa-sm"></i> object-detection</a>   <a href="/blog/tag/tutorial"> <i class="fa-solid fa-hashtag fa-sm"></i> tutorial</a>     ·   <a href="/blog/category/object-detection"> <i class="fa-solid fa-tag fa-sm"></i> object-detection</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This started as a summary of <a href="https://medium.com/towards-data-science/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" rel="external nofollow noopener" target="_blank">this nice tutorial</a>, but has since then become its own thing.</p> <ul> <li><a href="#prerequisites">Prerequisites</a></li> <li><a href="#annotating-images">Annotating images</a></li> <li><a href="#serializing-the-dataset">Serializing the dataset</a></li> <li><a href="#preparing-the-training-pipeline">Preparing the training pipeline</a></li> <li><a href="#training-the-network">Training the network</a></li> <li><a href="#final-tips">Final Tips</a></li> </ul> <h2 id="prerequisites">Prerequisites</h2> <ol> <li> <p>Choose a TensorFlow installation. TensorFlow 1 and 2 have different neural networks avaliable, so check <a href="TF1-zoo">here</a> and <a href="TF2-zoo">here</a> to make your choice.</p> <ul> <li> <strong>Tip:</strong> if you opt for one of the TF1 models, please note that the Object Detection API is only officialy compatible with TF 1.15.O, which works only with CUDA 10.0 (unless you compile from source). From personal experience, I know that all versions of TF from 1.12 and backwards do not work with the Object Detection API anymore.</li> </ul> </li> <li> <a href="https://www.tensorflow.org/install/" rel="external nofollow noopener" target="_blank">Install TensorFlow</a>.</li> <li>Download the TensorFlow <a href="https://github.com/tensorflow/models" rel="external nofollow noopener" target="_blank">models repository</a> and install the Object Detection API <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1.md" rel="external nofollow noopener" target="_blank">[TF1]</a> <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md" rel="external nofollow noopener" target="_blank">[TF2]</a>.</li> </ol> <h2 id="annotating-images">Annotating images</h2> <ol> <li> <p>Install <a href="https://github.com/tzutalin/labelImg" rel="external nofollow noopener" target="_blank"><em>labelImg</em></a>. This is a Python package, which means you can install it via pip, but the one from GitHub is better.</p> </li> <li> <p>Annotate your dataset using <em>labelImg</em>. Each image you annotate will have its annotations saved to an individual XML file with the name of the original image file and the <code class="language-plaintext highlighter-rouge">.xml</code> extension.</p> </li> </ol> <h2 id="serializing-the-dataset">Serializing the dataset</h2> <p>For these steps, I’ll recommend a collection of scripts I made, which are available in <a href="util-scripts">this repository</a>. All the scripts mentioned in this section receive arguments from the command line and have help messages through the <code class="language-plaintext highlighter-rouge">-h/--help</code> flags. Also check the README from the repo they come from to get more details, if needed.</p> <ol> <li> <p>Use <a href="https://github.com/douglasrizzo/detection_util_scripts/blob/master/generate_csv.py" rel="external nofollow noopener" target="_blank">this script</a> to convert the XML files generated by labelImg into a single CSV file.</p> <ul> <li> <strong>Optional:</strong> Use <a href="https://github.com/douglasrizzo/detection_util_scripts/blob/master/generate_train_eval.py" rel="external nofollow noopener" target="_blank">this script</a> to separate the CSV file into two, one with training examples and one with evaluation examples. Let's call them <code class="language-plaintext highlighter-rouge">train.csv</code> and <code class="language-plaintext highlighter-rouge">val.csv</code>. Images will be selected randomly and there are options to stratify examples by class, making sure that objects from all classes are present in both datasets. The usual proportions are 75% to 80% of the annotated objects used for training and the rest for the evaluation dataset.</li> </ul> </li> <li> <p>Create a “label map” for your classes. You can check <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/data" rel="external nofollow noopener" target="_blank">some examples</a> to understand what they look like. You can also generate one from your original CSV file with <a href="https://github.com/douglasrizzo/detection_util_scripts/blob/master/generate_pbtxt.py" rel="external nofollow noopener" target="_blank">this script</a>.</p> </li> <li> <p>Use <a href="https://github.com/douglasrizzo/detection_util_scripts/blob/master/generate_tfrecord.py" rel="external nofollow noopener" target="_blank">this script</a> to convert each of your CSV files into two TFRecord files (e.g. <code class="language-plaintext highlighter-rouge">train.record</code> and <code class="language-plaintext highlighter-rouge">eval.record</code>), a serialized data format that TensorFlow is most familiar with. You’ll need to point to the directory where the image files are stored and to the label map generated in the previous step.</p> <ul> <li> <strong>Tip:</strong> if you notice mistakes during the creation of these files, you can check their contents and compare to the ones in <a href="https://github.com/douglasrizzo/detection_util_scripts/tree/master/examples" rel="external nofollow noopener" target="_blank">these examples</a>.</li> </ul> </li> </ol> <h2 id="preparing-the-training-pipeline">Preparing the training pipeline</h2> <ol> <li> <p>Download the neural network model of choice from either the Detection Model Zoo <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md" rel="external nofollow noopener" target="_blank">[TF1]</a><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="external nofollow noopener" target="_blank">[TF2]</a> or from the models trained for classification available <a href="https://github.com/tensorflow/models/tree/master/research/slim#Pretrained" rel="external nofollow noopener" target="_blank">here</a> and <a href="https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet#pretrained-models" rel="external nofollow noopener" target="_blank">here</a>. This is the step in which your choice of TensorFlow version will make a difference. From my experience, many of the classification models work with TF 1.15, but I am not aware if they work with TF 2.</p> </li> <li> <p>Provide a training pipeline, which is a file with <code class="language-plaintext highlighter-rouge">.config</code> extension that describes the training procedure. The models provided in the Detection Zoo come with their own pipelines inside their <code class="language-plaintext highlighter-rouge">.tar.gz</code> file, but the classification models do not. In this situation, your options are to:</p> <ul> <li>download one that is close enough from <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs" rel="external nofollow noopener" target="_blank">here</a> (I have succesfully done that to train classification MobileNets V1, V2 and V3 for detection).</li> <li>create your own, by following <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md" rel="external nofollow noopener" target="_blank">this tutorial</a>.</li> </ul> <p>The pipeline config file has some fields that must be adjusted before training is started. The first thing you’ll definitely want to keep an eye on is the <code class="language-plaintext highlighter-rouge">num_classes</code> attribute, which you’ll need to change to the number of classes in your personal dataset.</p> <p>Other important fields are the ones with the <code class="language-plaintext highlighter-rouge">PATH_TO_BE_CONFIGURED</code> string. In these fields, you’ll need to point to the files they ask for, such as the label map, the training and evaluation TFRecords and the neural network checkpoint, which is a file with an extension like <code class="language-plaintext highlighter-rouge">.ckpt</code> or <code class="language-plaintext highlighter-rouge">.ckpt.data-####-of-####</code>. This file also comes with the <code class="language-plaintext highlighter-rouge">.tar.gz</code> file.</p> <p>In case you are using a model from the Detection Zoo, set the <code class="language-plaintext highlighter-rouge">fine_tune_checkpoint_type</code> field to <code class="language-plaintext highlighter-rouge">"detection"</code>, otherwise, set it to <code class="language-plaintext highlighter-rouge">"classification"</code>.</p> <p>There are additional parameters that may affect how much RAM is consumed by the training process, as well as the quality of the training. Things like the batch size or how many batches TensorFlow can prefetch and keep in memory may considerably increase the amount of RAM necessary, but I won’t go over those here as there is too much trial and error in adjusting those.</p> </li> </ol> <h2 id="training-the-network">Training the network</h2> <ol> <li> <p>Train the model. To do it locally, follow the steps available here: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_training_and_evaluation.md" rel="external nofollow noopener" target="_blank">[TF1]</a><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md" rel="external nofollow noopener" target="_blank">[TF2]</a>.</p> <p><strong>Optional:</strong> in order to check training progress, TensorBoard can be started pointing its <code class="language-plaintext highlighter-rouge">--logdir</code> to the <code class="language-plaintext highlighter-rouge">--model_dir</code> path from the previous step.</p> </li> <li> <p>Export the network, like <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md" rel="external nofollow noopener" target="_blank">this</a>.</p> <p><strong>Tip:</strong> if your training completes successfully but you get a scary “data loss error” like <a href="https://github.com/tensorflow/models/issues/2676" rel="external nofollow noopener" target="_blank">this one</a> when exporting, make sure you point the export script to the checkpoint file accordingly. For example, if your checkpoint file is named <code class="language-plaintext highlighter-rouge">model.ckpt-50000.data-00000-of-00001</code> or <code class="language-plaintext highlighter-rouge">model.ckpt.data-00000-of-00001</code>, you have to pass the file name as <code class="language-plaintext highlighter-rouge">model.ckpt-50000</code> or <code class="language-plaintext highlighter-rouge">model.ckpt</code>, respectively.</p> </li> <li> <p>In the directory where the export script was pointed to, a file called <code class="language-plaintext highlighter-rouge">frozen_inference_graph.pb</code> will be created. Use this file alongside the label map to detect objects in your application. An example of how to achieve this can be found in <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb" rel="external nofollow noopener" target="_blank">this notebook</a> from the Models repository. Alternatively, you can give my package <a href="https://douglasrizzo.com.br/dodo_detector/" rel="external nofollow noopener" target="_blank">dodo detector</a> a try, which uses these same files, but abstracts the inner workings of TensorFlow. You can see it in action in <a href="https://gist.github.com/douglasrizzo/fd4cff7cdf53b3ad08d67f736e5017ea" rel="external nofollow noopener" target="_blank">this Gist</a>.</p> </li> </ol> <h2 id="final-tips">Final Tips</h2> <p>In the <em>data augmentation</em> section of the training pipeline, some options can be added or removed to try and make the training better. Some options are listed <a href="https://stackoverflow.com/a/46901051" rel="external nofollow noopener" target="_blank">here</a>.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/03/local-gemma-chatbot-langchain-ollama/">Running a Gemma-powered question-answering chatbot locally with LangChain + Ollama</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/02/llm-qa-obsidian-rag/">Answering questions from an Obsidian database with LLMs + RAG</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/07/ts-queue-experiments/">Using task-spooler to queue experiments on Linux</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/05/cpp-structs-classes/">In C++, classes and structs are the same thing</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Douglas De Rizzo Meneghetti. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>