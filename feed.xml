<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://douglasrizzo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://douglasrizzo.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-10T17:59:25+00:00</updated><id>https://douglasrizzo.github.io/feed.xml</id><title type="html">Douglas Meneghetti</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Running a Gemma-powered question-answering chatbot locally with LangChain + Ollama</title><link href="https://douglasrizzo.github.io/blog/2024/03/local-gemma-chatbot-langchain-ollama/" rel="alternate" type="text/html" title="Running a Gemma-powered question-answering chatbot locally with LangChain + Ollama"/><published>2024-03-01T00:00:00+00:00</published><updated>2024-03-01T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2024/03/local-gemma-chatbot-langchain-ollama</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2024/03/local-gemma-chatbot-langchain-ollama/"><![CDATA[<p>Last week, I started my quest to build my first LLM-powered chatbot that runs locally and executes RAG on my <a href="https://obsidian.md/">Obsidian</a> document base. You can see it <a href="/blog/2024/02/llm-qa-obsidian-rag/">here</a>.</p> <p>This post is a follow-up to that one. The highlights of this one are:</p> <ol> <li>I will test the brand new <a href="https://ai.google.dev/gemma">Google Gemma</a> family of models and qualitatively compare it to a Mistral model of same size.</li> <li>The chatbot will run 100% locally in my computer with a GTX 1070, 7h gen i7 and 32 GB of RAM, using Chroma for the vector store and <a href="https://ollama.com/">Ollama</a> for the models.</li> <li>Unlike in the <a href="/blog/2024/02/llm-qa-obsidian-rag/">previous post</a>, we’ll configure the correct prompt templates for our instruction-tuned models.</li> </ol> <p>Also, since <a href="/blog/2024/02/llm-qa-obsidian-rag/">my last post</a>, I’ve refactored the code base in its current state as both a Python package and a command-line tool, which you can find in <a href="https://github.com/douglasrizzo/langsidian">this link</a>. This is what I used to run the experiments shown in this page. A sample notebook is provided <a href="https://github.com/douglasrizzo/langsidian/blob/master/2%20-%20Langsidian%20as%20a%20package.ipynb">here</a> and <a href="https://github.com/douglasrizzo/langsidian/tree/master/langsidian">the underlying code</a> is &lt; 200 lines long!</p> <h2 id="test-driving-gemma-7b">Test-driving Gemma-7b</h2> <p>A few days ago, Google released <a href="https://ai.google.dev/gemma">Gemma</a>, a family of lightweight models the same size as Mistral-7b, the one I was already using.</p> <p>My first attempt at loading Gemma-7b was through <a href="https://huggingface.co/google/gemma-7b-it">Hugging Face</a>. However, it needs extra configuration to fit in my memory, i.e. float16/bfloat16 quantization with PyTorch, or 8bit/4bit quantization with bitsandbytes. Also, the model files are huge, totalling 20 GB.</p> <p>For now, let’s familiarize ourselves with Ollama, which is simpler, and leave the Hugging Face ecosystem for later.</p> <h2 id="enter-ollama">Enter Ollama</h2> <p>It turns out a very widespread way of running models locally is through <a href="https://ollama.com/">Ollama</a>, which is very simple to install on Linux.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-fsSL</span> https://ollama.com/install.sh | sh
</code></pre></div></div> <p>Ollama has a Docker-like interface (it was made by <a href="https://twitter.com/jmorgan">an ex-Docker employee</a>) and models can be downloaded using their names and some basic tags. Downloaded models can be executed via python using their <a href="https://pypi.org/project/ollama/">official library</a>.</p> <p>With that, I decided to stop using models from multiple libraries and frameworks and run all of them in Ollama. The commands below downloaded Mistral-7b, Gemma-7b, and a text embedding model from <a href="https://home.nomic.ai/">Nomic.AI</a>.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama pull mistral:7b-instruct
ollama pull gemma:7b-instruct
ollama pull nomic-embed-text
</code></pre></div></div> <p>The model files downloaded by Ollama are considerably smaller (each 7b model fit in a single 5GB file). They also loaded into my GPU memory, alongside the embedding model.</p> <h2 id="configuring-the-correct-prompt-templates">Configuring the correct prompt templates</h2> <p>It turns out the prompt templates, especially for Instruct models, need to use the correct tokens and that is not done automatically by LangChain or any other library.</p> <p>I went after the correct templates on the Ollama website. They are shown below. Contrast with <a href="/blog/2024/02/llm-qa-obsidian-rag/#retrieval-qa-with-custom-prompt-template">my last post</a>, in which I copied an internal prompt from LangChain, which was not suitable for any specific model.</p> <p>While tweaking the contents of the prompt template, I realized how much variability in the responses I got from only minor tweaks. For example, if I told Gemma something like <em>“if you don’t know the answer, just say you don’t know and not make anything up”</em>, the model would just refuse to answer any questions, even if the information was present in the retrieved text chunks. To make the comparison fair, I also removed the same section from the mistral prompt template, which I used in the <a href="/blog/2024/02/llm-qa-obsidian-rag/#retrieval-qa-with-custom-prompt-template">previous post</a>.</p> <h3 id="mistral-prompt-template">Mistral prompt template</h3> <p>Sources: <a href="https://ollama.com/library/mistral:7b-instruct">Ollama</a> and <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Hugging Face Hub</a>.</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;s&gt;[INST] Use the following pieces of context to answer the question at the end. Present a well-formatted answer, using Markdown if possible. Don't go over three paragraphs when answering.
---
{context}
---
Question: {question} [/INST]
</code></pre></div></div> <h3 id="gemma-prompt-template">Gemma prompt template</h3> <p>Sources: <a href="https://huggingface.co/google/gemma-7b-it">Ollama</a> and <a href="https://ollama.com/library/gemma:7b-instruct">Hugging Face Hub</a>.</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;start_of_turn&gt;user
Use the following pieces of context to answer the question at the end. Present a well-formatted answer, using Markdown if possible. Don't go over three paragraphs when answering.
---
{context}
---
Question: {question}&lt;end_of_turn&gt;
&lt;start_of_turn&gt;model
</code></pre></div></div> <h2 id="tweaking-rag-parameters">Tweaking RAG parameters</h2> <p>One problem I was having was that performing maximal marginal similarity on a small number of chunks (e.g. 3) tended to result only a single helpful text chunk. To fix that I</p> <ul> <li>reduced the chunk sizes</li> <li>retrieved more chunks</li> </ul> <p>Some final tweaking that made the output of both models better was using the following parameters:</p> <ul> <li>Chunk size: 400 characters</li> <li>Chunk overlap: 50 characters</li> <li>Chunks returned by similarity for <a href="https://python.langchain.com/docs/modules/model_io/prompts/example_selector_types/mmr">MMR</a> search: 10</li> <li>Final number of chunks returned by <a href="https://python.langchain.com/docs/modules/model_io/prompts/example_selector_types/mmr">MMR</a>: 6</li> <li><a href="https://python.langchain.com/docs/modules/model_io/prompts/example_selector_types/mmr">MMR</a> $\lambda$ (0 = maximum diversity among chunks; 1 = no diversity): 0.7</li> </ul> <h2 id="running-the-models">Running the models</h2> <p>Since my last post, I’ve refactored the code base in its current state as both a Python package and a command-line tool, which you can find in <a href="https://github.com/douglasrizzo/langsidian">this link</a>. This is what I used in the construction of this post.</p> <p>The snippet below (which is also available as a <a href="https://github.com/douglasrizzo/langsidian/blob/master/2%20-%20Langsidian%20as%20a%20package.ipynb">Jupyter Notebook</a>) showcases how to instantiate and talk to the LLM-powered Q&amp;A bot:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="n">langsidian</span> <span class="kn">import</span> <span class="n">ChatBot</span><span class="p">,</span> <span class="n">DocumentBase</span>

<span class="n">bot</span> <span class="o">=</span> <span class="nc">ChatBot</span><span class="p">(</span>
  <span class="n">docs_path</span><span class="o">=</span><span class="p">(</span><span class="n">Path</span><span class="p">.</span><span class="nf">home</span><span class="p">(</span><span class="sh">"</span><span class="s">Documents</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Obsidian</span><span class="sh">"</span><span class="p">)),</span>
  <span class="n">vectorstore_db_path</span><span class="o">=</span><span class="nc">Path</span><span class="p">(</span><span class="sh">"</span><span class="s">docs/chroma</span><span class="sh">"</span><span class="p">),</span>
  <span class="n">document_type</span><span class="o">=</span><span class="n">DocumentBase</span><span class="p">.</span><span class="n">OBSIDIAN</span><span class="p">,</span>
  <span class="n">model_type</span><span class="o">=</span><span class="sh">"</span><span class="s">mistral:7b-instruct</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="o">=</span><span class="sh">"</span><span class="s">nomic</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">q</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What is zero-shot learning?</span><span class="sh">"</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">**Question: </span><span class="si">{</span><span class="n">q</span><span class="si">}</span><span class="s">**</span><span class="se">\n\n</span><span class="s"> Answer: </span><span class="si">{</span><span class="n">bot</span><span class="p">.</span><span class="nf">answer</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="sh">"</span><span class="se">\n\n</span><span class="s">---</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>It can also be executed as a standalone module. The document path and model name can be selected with command-line arguments:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> langsidian
</code></pre></div></div> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Prompt]: Who were the authors of the Deep Q-Network paper?
[Assistant]:  The authors of the Deep Q-Network paper were Mnih, Vaswani, Graves, et al. (2015). You can find their paper here: &lt;https://arxiv.org/abs/1312.5602&gt;.
</code></pre></div></div> <h2 id="results">Results</h2> <p>Below, I asked the same questions to both Mistral-7b-it and Gemma-7b-it, giving them access to my Obsidian document base, whose chunks are now embedded using <a href="https://blog.nomic.ai/posts/nomic-embed-text-v1">Nomic Embed</a>.</p> <p>Analyzing the output qualitatively, I found that Mistral tends to give more informative and helpful answers. It also makes better use of the information in the chunks provided by the RAG procedure, creating richer answers, whereas Gemma tends to repeat itself or cut answers short when it hits a dead-end such as in the answer for <a href="#gemma-7b-1">this question</a>.</p> <p>Also, in <a href="#gemma-7b">the first question</a>, Gemma explained terms that may have been in the context chunks recovered for RAG (such as $a’$ and $\pi_*$), but they did not appear in its final answer, which would definitely confuse users in a conversation.</p> <hr/> <h3 id="question-give-me-the-equation-for-the-action-value-function-update-and-explain-its-terms">Question: Give me the equation for the action value function update and explain its terms.</h3> <h4 id="mistral-7b">Mistral-7b</h4> <p>The equation for the action-value function update using the n-step return is as follows:</p> \[Q_{t+n}(S_t, A_t) \leftarrow Q_{t+n-1}(S_t, A_t) + \alpha [G_{t:t+n} - \gamma^n Q_{t+n-1}(S_t, A_t)]\] <p>This equation is a form of the Bellman equation for the action-value function. Let’s break down its terms:</p> <ul> <li>$Q_{t+n}$: The action-value function at time step $t+n$ for state-action pair $(S_t, A_t)$.</li> <li>$\alpha$: The learning rate or step size, which determines how much new information is incorporated in each update.</li> <li>$G_{t:t+n}$: The n-step return from time step t to time step $t+n$. It’s the total reward obtained by following policy $\pi$ from state $S_t$ and taking action $A_t$, plus all the discounted future rewards, i.e., $G_{t:t+n} = R_{t+1:t+n}+ \gamma V_{\pi}(S_{t+n})$</li> <li>$\gamma$: The discount factor, which is used to discount future rewards by a certain percentage to make them present values.</li> <li>$Q_{t+n-1}$: The old estimate of the action-value function at time step $t+n-1$ for state-action pair $(S_t, A_t)$.</li> </ul> <p>This update rule aims to minimize the difference between the current and new estimates of $Q(S_t,A_t)$, gradually improving the estimation as more samples are collected.</p> <h4 id="gemma-7b">Gemma-7b</h4> <p><strong>Equation for Action Value Function Update:</strong></p> \[Q_{t+n}(S_t, A_t) \doteq Q_{t+n-1}(S_t, A_t) + \alpha [G_{t:t+n} - \gamma^n Q_{t+n-1}(S_t, A_t)]\] <p><strong>Explanation of Terms:</strong></p> <ul> <li><strong>$Q_{t+n}(S_t, A_t)$:</strong> The action-value function at time $t+n$ for state $S_t$ and action $A_t$.</li> <li><strong>$Q_{t+n-1}(S_t, A_t)$:</strong> The action-value function at time $t+n-1$ for state $S_t$ and action $A_t$.</li> <li><strong>$\alpha$:</strong> The learning rate, which controls the rate of learning.</li> <li><strong>$G_{t:t+n}$:</strong> The n-step return, which is the total reward from time $t$ to time $t+n$.</li> <li><strong>$\gamma$:</strong> The discount factor, which accounts for the value of future rewards.</li> <li><strong>$a’$:</strong> The action that is not taken at time $t$.</li> <li><strong>$\pi_*$:</strong> The optimal policy.</li> </ul> <p><strong>Note:</strong> This equation is for the action-value function update in Q-learning, not the state-value function update.</p> <hr/> <h3 id="question-what-is-the-architecture-of-the-deep-q-networks">Question: What is the architecture of the Deep Q-Networks?</h3> <h4 id="mistral-7b-1">Mistral-7b</h4> <p>The Deep Q-Network (DQN) architecture uses a deep neural network to approximate the Q* function in reinforce learning. The input to the network are 4 frames of 84x84 pixel screenshots from Atari 2600 games, only using the luminance values of the pixels. The network then uses three convolutional layers to learn visual representations of the game states. The output of the neural network is the Q values of all possible actions for each state, ranging from 4 to 18.</p> <p>This architecture builds upon the Q-learning algorithm, which aims to find the optimal policy by iteratively improving the Q values based on observed state-action pairs and their corresponding rewards. However, directly applying this algorithm to deep neural networks with large input spaces is infeasible due to the computational demands.</p> <p>To overcome this challenge, DQN uses experiences from multiple frames and applies a target network for more stable learning. The target network is updated periodically to match the weights of the online network, ensuring that the Q values in the target network do not change too frequently during training. Additionally, the authors use experience replay, where they store transitions in a buffer and sample them randomly to train the network, which helps in reducing correlation between consecutive samples and improving stability.</p> <p>These architectural enhancements allowed DQN to learn complex visual representations of Atari games, achieve human-level performance on several benchmark tasks, and set a new standard for deep reinforce learning research.</p> <h4 id="gemma-7b-1">Gemma-7b</h4> <p>The text describes the architecture of Deep Q-Networks, which uses a deep neural network to approximate the Q* function. The neural network has three convolution layers to learn visual representations of the game states.</p> <p>The text does not describe the architecture of the convolutional layers, therefore I cannot answer the question.</p> <hr/> <h3 id="question-what-is-the-difference-between-causal-language-modeling-and-masked-language-modeling">Question: What is the difference between causal language modeling and masked language modeling?</h3> <h4 id="mistral-7b-2">Mistral-7b</h4> <p>Causal and masked language modeling are two different methods used for pre-training language models.</p> <p>In <strong>causal language modeling</strong>, also known as autoregressive language modeling, the language model is trained to predict the next token in a sequence given the context of the previous tokens. The model has access to the entire sequence during training and prediction, and its task is to generate the next token based on the context provided. However, since there is no ground truth available during inference, this can lead to a discrepancy between training and inference, known as Exposure Bias. This issue can be addressed through techniques like Curriculum learning.</p> <p>In <strong>masked language modeling</strong>, also known as Masked Language Modeling (MLM), tokens are randomly masked at training time and the model is trained to reconstruct the original text by predicting the masked tokens. For instance, in the sentence “the teacher teaches the student”, the word “teaches” might be masked as “<MASK>". During training, the model is presented with the masked token and its context, and its task is to learn to fill in the masked token based on the context provided. BERT is an example of a masked language model. The main difference between causal and masked language modeling lies in how the models are trained and what they are optimized for: causal models predict the next token given the context, while masked models learn to fill in missing tokens based on their context.</MASK></p> <p>Sources: DeepLearning.AI Natural Language Processing Specialization, Generative AI with Large Language Models.</p> <h4 id="gemma-7b-2">Gemma-7b</h4> <p>Causal language modeling and masked language modeling are two methods for pre-training language models.</p> <p>Causal language modeling allows the model to see the first tokens of the sequence and its task is to predict the next token. Masked language modeling, on the other hand, randomly masks tokens at training time and the model is trained to reconstruct the original text by predicting the masked tokens.</p> <p>The main difference between causal language modeling and masked language modeling is that in causal language modeling, the model has access to the first tokens of the sequence and its task is to predict the next token, while in masked language modeling, the model is trained to reconstruct the original text by predicting the masked tokens.</p> <hr/> <h3 id="question-what-is-zero-shot-learning">Question: What is zero-shot learning?</h3> <h4 id="mistral-7b-3">Mistral-7b</h4> <p>Zero-shot learning is a concept used in machine learning, specifically in the context of Generative AI and Large Language Models (LLMs), to describe the capability of an LLM to predict classes it was not explicitly trained on without being given any explicit examples during training or at inference time. In other words, the model makes predictions based on its existing knowledge, rather than learning from new examples provided in real-time. This is in contrast to few-shot learning, where the model is given a few examples of the task it’s expected to perform before being presented with the actual task. Zero-shot learning requires a large and diverse dataset for the model to generalize effectively to unseen classes or concepts.</p> <p>One limitation of zero-shot learning is that it may not be as effective as few-shot learning, especially when dealing with complex tasks or rare classes. Another limitation is that it relies heavily on the quality and representativeness of the training data for making accurate predictions. However, since zero-shot learning allows models to execute new tasks without being given any explicit examples, it can be beneficial in scenarios where acquiring labeled data is difficult, costly, or time-consuming.</p> <p>Regarding your additional question: In Q-learning, importance sampling is not used because it is an off-policy reinforce learning algorithm that learns from a sequence of state-action pairs (trajectories) generated by a policy π, which may not be the optimal one. The goal is to estimate the action-value function Q(s,a), and importance sampling would introduce additional complexity without significant benefits in this context.</p> <h4 id="gemma-7b-3">Gemma-7b</h4> <p>Zero-shot learning is the capability of a model to predict classes it was not explicitly trained on. In the context of Generative AI and LLMs, zero-shot learning refers to the capability of an LLM to execute new tasks without being given any explicit examples.</p> <p>In zero-shot learning, the model is given no examples of the task it is expected to perform, and it must generalize from its previous experiences to complete the task. This contrasts with few-shot learning, which involves providing the model with a few examples of the task it is expected to perform.</p> <p>For example, if you ask a model to classify a review as positive or negative, and it has never seen a review with that sentiment before, zero-shot learning would involve the model making a generalization based on its previous experiences to determine whether the review is positive or negative.</p> <hr/> <h3 id="question-explain-to-me-the-concept-of-bucketing-in-rnns">Question: Explain to me the concept of bucketing in RNNs</h3> <h4 id="mistral-7b-4">Mistral-7b</h4> <p>Bucketing in Recurrent Neural Networks (RNNs) is a technique used for batching sequences while minimizing padding. The main goal is to process sequences of varying lengths efficiently and maintain a consistent batch size during training. Here’s a step-by-step explanation:</p> <ol> <li><strong>Divide data into buckets:</strong> Divide the input data into <code class="language-plaintext highlighter-rouge">m</code> buckets based on sequence lengths. Each bucket represents a specific range of sequence lengths.</li> <li><strong>Sample sequences from a single bucket:</strong> For each batch, sample all sequences from only one of the buckets. This ensures that most sequences in a batch have similar lengths, reducing the need for extensive padding.</li> <li><strong>Pad sequences to the largest one:</strong> Pad all sequences in the batch to match the size of the longest sequence. This guarantees that every sequence receives the same amount of processing during each time step.</li> </ol> <p>Bucketing is an essential technique when dealing with sequence data, as it helps to minimize padding and improve training efficiency. However, it might require more computational resources due to the need to process multiple buckets for generating batches over time.</p> <p>It’s important to note that this method assumes that sequences within a bucket are independent of one another. If there is any dependence between sequences in a bucket, this assumption would not hold true, and other data processing techniques might be required.</p> <h4 id="gemma-7b-4">Gemma-7b</h4> <p>Bucketing in RNNs is a technique for batching sequences in a way that minimizes padding. The idea is to group sequences of similar length into buckets and then process the buckets separately.</p> <p>The process of bucketing involves dividing the data into buckets, sampling sequences from a single bucket, and padding all sequences in a batch to the size of the largest sequence in the batch. This technique is useful for RNNs because it allows for the efficient processing of sequences of varying lengths.</p> <p>The technique is illustrated in the provided text with two images. The first image shows the process of dividing the data into buckets, and the second image shows the process of padding the sequences in a batch.</p> <hr/> <h3 id="question-what-is-a-named-entity">Question: What is a named entity?</h3> <h4 id="mistral-7b-5">Mistral-7b</h4> <p>A named entity is a real-world object that can be denoted with a proper name, examples include persons, locations, organizations, products, geographical entities, geopolitical entities, time indicators, artifacts, events, and natural phenomena. Named Entity Recognition (NER) systems are used to automatically locate named entities from unstructured text. This process is important for various applications such as improving search engine efficiency by scanning websites and storing named entities for later matching with user queries, and enhancing recommendation systems by extracting named entities from a user’s search history to identify their interests.</p> <p>For instance, in the sentence “Sharon flew to Miami on Friday,” the named entities are “Sharon” (person), “Miami” (location), and “Friday” (time indicator). NER systems can accurately identify and tag these named entities within the text. The remaining tokens that do not represent named entities are typically tagged as filler words or <code class="language-plaintext highlighter-rouge">O</code>.</p> <h4 id="gemma-7b-5">Gemma-7b</h4> <p>A named entity is a real-world object that can be denoted with a proper name. It can be abstract or have a physical existence. Examples of named entities include people, locations, organizations, and products.</p> <p>Named entities are extracted from text and are used to identify and classify named objects in a sentence. They are used in various applications, such as search engine efficiency, recommendation systems, and information extraction.</p> <p>In the text provided, the sentence “Sharon flew to Miami on Friday” would have the named entities “Sharon,” “Miami,” and “Friday.”</p> <h2 id="conclusions">Conclusions</h2> <p>On this post, I show you how I locally executed an LLM-powered Q&amp;A chatbot that performs RAG on an Obsidian, using Mistral-7b and Gemma-7b instruction fine-tuned models as well as Nomic-Embed, all provided by Ollama.</p> <p>I showed you how I did and you can:</p> <ul> <li>Install Ollama;</li> <li>Download Ollama models;</li> <li>Configure prompt templates for the instruction-tuned versions of Gemma and Mistral, and;</li> <li>Configure some search parameters to get better chunks and RAG results.</li> </ul>]]></content><author><name></name></author><category term="llms"/><category term="python"/><category term="langchain"/><category term="ollama"/><category term="google-gemma"/><category term="mistral"/><summary type="html"><![CDATA[Last week, I started my quest to build my first LLM-powered chatbot that runs locally and executes RAG on my Obsidian document base. You can see it here.]]></summary></entry><entry><title type="html">Answering questions from an Obsidian database with LLMs + RAG</title><link href="https://douglasrizzo.github.io/blog/2024/02/llm-qa-obsidian-rag/" rel="alternate" type="text/html" title="Answering questions from an Obsidian database with LLMs + RAG"/><published>2024-02-19T00:00:00+00:00</published><updated>2024-02-19T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2024/02/llm-qa-obsidian-rag</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2024/02/llm-qa-obsidian-rag/"><![CDATA[<p>This notebook presents a proof-of-concept on how to create a question-answering bot powered by an LLM and with knowledge extracted from actual documents, more specifically, a collection of notes from Obsidian.</p> <p>I am going to run all experiments locally, using a 7th gen i7, an NVIDIA GTX 1070 and 32 GBs of RAM.</p> <p>A lot of the heavy lifting will be done by the <a href="https://www.langchain.com/">LangChain</a> package, which I am on the process of learning to use.</p> <p>On the road to building this Q&amp;A bot, we will be introduced to many concepts:</p> <ol> <li>Document loading</li> <li>Text data cleaning using regex</li> <li>Splitting of Markdown documents into text chunks</li> <li>Sentence embeddings</li> <li>Vector stores</li> <li>Similarity search using cosine similarity between embedding vectors</li> <li>maximal marginal relevance search</li> <li>Self-query retrieval</li> <li>Contextual compression retrieval</li> <li>Question-answering with retrieval augmented generation</li> <li>Question-answering with retrieval augmented generation and custom templates</li> </ol> <p>So that no one gets lost, the following diagram explains how the whole pipeline to get to our final Q&amp;A bot (and how this notebook) works:</p> <p><img src="/assets/img/langsidian.png" alt="My happy picture"/></p> <h2 id="prerequisites">Prerequisites</h2> <ol> <li>You can find the environment.yml file to create a conda env with the necessary dependencies to run the notebook.</li> <li> <p>You should download a model from the GPT4All website and save it on <code class="language-plaintext highlighter-rouge">./models/my_little_llm.gguf</code>. The one below is the one I used.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> wget https://gpt4all.io/models/gguf/mistral-7b-openorca.Q4_0.gguf <span class="nt">-O</span> models/my_little_llm.gguf
</code></pre></div> </div> </li> </ol> <h2 id="loading-documents">Loading documents</h2> <p>Here I used the <code class="language-plaintext highlighter-rouge">ObsidianLoader</code> document loader and point it to the directory that contains all my notes in Markdown format.</p> <p>We can see I have ~500 text files.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="n">docs_path</span> <span class="o">=</span> <span class="p">(</span><span class="n">Path</span><span class="p">.</span><span class="nf">home</span><span class="p">()</span> <span class="o">/</span> <span class="sh">"</span><span class="s">Documents</span><span class="sh">"</span> <span class="o">/</span> <span class="sh">"</span><span class="s">Obsidian</span><span class="sh">"</span><span class="p">).</span><span class="nf">absolute</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">ObsidianLoader</span>

<span class="n">loader</span> <span class="o">=</span> <span class="nc">ObsidianLoader</span><span class="p">(</span><span class="n">docs_path</span><span class="p">,</span> <span class="n">collect_metadata</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">UTF-8</span><span class="sh">"</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Loaded </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="si">}</span><span class="s"> docs</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Encountered non-yaml frontmatter


Loaded 499 docs
</code></pre></div></div> <p>Let’s take a peek at one of the documents. We can see it has the textual content itself, as well as some metadata. The <code class="language-plaintext highlighter-rouge">ObsidianLoader</code> includes file properties from Obsidian documents, such as tags, dates and aliases, as part of the metadata.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">docs</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Document(page_content='A method for pre-training [[language model]]s in which the model has access to the first tokens of the sequence and its task is to predict the next token.\n\nThe following examples depict how a single sequence can be turned into multiple training examples:\n\n1. `&lt;START&gt;` → `the`\n1. `&lt;START&gt; the` → `teacher`\n1. `&lt;START&gt; the teacher` → `teaches`\n1. `&lt;START&gt; the teacher teaches` → `the`\n1. `&lt;START&gt; the teacher teaches the` → `student`\n1. `&lt;START&gt; the teacher teaches the student` → `&lt;END&gt;`\n\nModels trained using this method have access to the full sequence of tokens at inference time, making them appropriate for non-generative tasks that revolve around processing a sequence of tokens as a whole, for example:\n\n- [[Sentiment Analysis]]\n- [[Named entity recognition]]\n- [[Word classification]]\n\n[[Bidirectional Encoder Representation from Transformers|BERT]] is an example of a masked language model. Example from [[Bidirectional Encoder Representation from Transformers|BERT]]: Choose 15% of the tokens at random: mask them 80% of the time, replace them with a random token 10% of the time, or keep as is 10% of the time.\n\n## Sources\n\n- [[DeepLearning.AI Natural Language Processing Specialization]]\n- [[Generative AI with Large Language Models]]', metadata={'source': 'Causal language modeling.md', 'path': '/home/dodo/Documents/Obsidian/Causal language modeling.md', 'created': 1700448369.2719378, 'last_modified': 1700448369.2719378, 'last_accessed': 1708267659.2105181, 'tags': 'area/ai/nlp/llm', 'date': '2023-11-19 23:41'})
</code></pre></div></div> <h2 id="cleaning-documents">Cleaning documents</h2> <p>Obsidian documents have some of their own Markdown flavor, like <code class="language-plaintext highlighter-rouge">[[Graph Neural Network|GNNs]]</code>, where <code class="language-plaintext highlighter-rouge">Graph Neural Network</code> is the name of a document and <code class="language-plaintext highlighter-rouge">GNNs</code> is what appears on the text. In cases like these, we want to keep only the second part.</p> <p>It also has full-on links, such as <code class="language-plaintext highlighter-rouge">[[grid world]]</code>, in which case we want to remove the double brackets.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !pip install google-re2
</span><span class="kn">import</span> <span class="n">re2</span>

<span class="n">docus</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">insane_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"</span><span class="s">\[\[([^\]]*?)\|([^\[]*?)\]\]</span><span class="sh">"</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re2</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">insane_pattern</span><span class="p">,</span> <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">new_doc</span> <span class="o">=</span> <span class="n">re2</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="n">insane_pattern</span><span class="p">,</span> <span class="sa">r</span><span class="sh">"</span><span class="s">\2</span><span class="sh">"</span><span class="p">,</span> <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">)</span>
        <span class="n">docus</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">,</span>
                <span class="n">new_doc</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span> <span class="o">=</span> <span class="n">new_doc</span>
    <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span> <span class="o">=</span> <span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">[[</span><span class="sh">"</span><span class="p">,</span> <span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">]]</span><span class="sh">"</span><span class="p">,</span> <span class="sh">""</span><span class="p">)</span>

<span class="nf">sorted</span><span class="p">(</span><span class="n">docus</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('- [[Intersection over Union|IoU]]', '- IoU')
</code></pre></div></div> <h2 id="splitting-documents">Splitting documents</h2> <p>This step splits the documents loaded in the previous step into smaller chunks.</p> <p>LangChain provides its own Markdown text splitter, which we are going to use.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">MarkdownTextSplitter</span>

<span class="n">splitter</span> <span class="o">=</span> <span class="nc">MarkdownTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>


<span class="nf">len</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1510
</code></pre></div></div> <p>Let’s take a peek at a chunk. They inherit the metadata of their parent document.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">splits</span><span class="p">[</span><span class="mi">542</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Document(page_content='# epsilon-soft policies\n\nAn $\\epsilon$-soft policy is a stochastic policy that always assigns a non-zero $\\frac{\\epsilon}{|A|}$ probability to all actions. These policies always perform some exploration.\n\nThe uniform random policy is an $\\epsilon$-soft policy. The epsilon-greedy policy also is.', metadata={'source': 'epsilon-soft policies.md', 'path': '/home/dodo/Documents/Obsidian/epsilon-soft policies.md', 'created': 1680669506.8282943, 'last_modified': 1680669506.8282943, 'last_accessed': 1708267660.780534, 'tags': 'area/ai/rl project/rl-spec', 'aliases': 'epsilon-soft policy', 'date': '2021-05-24 18:32'})
</code></pre></div></div> <h2 id="computing-embeddings-and-saving-them-to-a-vector-store">Computing embeddings and saving them to a vector store</h2> <p>To quickly search for text chunks, it is useful to precompute an embedding vector for each chunk and store it for future use.</p> <p>An embedding vector is a numerical vector that represents the text chunk. It allows us to compare chunks in the embedding space. Chunks with similar semantic meaning tend to have similar embedding vectors. This similarity can be computed using e.g. cosine similarity.</p> <p>My choice for embedding generator was <a href="https://www.sbert.net/">SentenceTransformers</a>, provided by Hugging Face, which runs locally.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !pip install sentence_transformers
</span><span class="kn">from</span> <span class="n">langchain.embeddings.huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="nc">HuggingFaceEmbeddings</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</code></pre></div></div> <p>Computed embedding vectors can be stored in <em>vector stores</em>. The one we will use in this project is <a href="https://docs.trychroma.com/">Chroma</a>. It is free, runs locally and is perfect for our small document base.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !pip install chromadb
</span><span class="kn">from</span> <span class="n">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>

<span class="n">persist_directory</span> <span class="o">=</span> <span class="sh">"</span><span class="s">docs/chroma/</span><span class="sh">"</span>
<span class="err">!</span><span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="p">.</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">chroma</span>  <span class="c1"># remove old database files if any
</span><span class="n">vectordb</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="n">persist_directory</span><span class="o">=</span><span class="n">persist_directory</span>
<span class="p">)</span>
<span class="n">vectordb</span><span class="p">.</span><span class="n">_collection</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1510
</code></pre></div></div> <h2 id="retrieval">Retrieval</h2> <p>Retrieval is the act of retrieving text chunks from our vector store, given an input prompt.</p> <p>Basic retrieval is performed by comparing the prompt embedding with those of the text chunks. More complex retrieval techniques involve calls to an LLM.</p> <h3 id="basic-retrieval">Basic retrieval</h3> <p>Let’s first test a retrieval technique based on similarity search in the vector store. Given a prompt, the procedure should return the most similar or relevant chunks in the vector database.</p> <p>The question below will be used as a test for everything else below in the notebook. It is related to reinforcement learning, an area in which I have a few hundred documents written on Obsidian. You can find more about the question <a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#value-functions">here</a> to see if our retrieval methods actually nail the answer.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">question</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What is the definition of the action value function?</span><span class="sh">"</span>
</code></pre></div></div> <p>The first example of retrieval is <em>similarity search</em>, which will convert the prompt into an embedding vector and compute the cosine similarity between the prompt embedding and the embeddings of all chunks in the vector store, returning the <em>k</em> most similar chunks.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">retrieved_docs</span> <span class="o">=</span> <span class="n">vectordb</span><span class="p">.</span><span class="nf">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">retrieved_docs</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="sh">"</span><span class="se">\n\n</span><span class="s">---</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The action-value function represents the expected return from a given state after taking a specific action and later following a specific policy.

$$q_{\pi}(s,a)=\mathbb{E}_{\pi}[G_t|S_t=s,A_t=a]$$

where $G_t$ is the Expected sum of future rewards.

---

A value function maps states, or state-action pairs, to expected returns.

- State-value function
- Action-value function

---

The state-value function represents the expected return from a given state, possibly under a given policy.

$$v(s)=\mathbb{E}[G_t|S_t=s]$$
$$v_{\pi}(s)=\mathbb{E}_{\pi}[G_t|S_t=s]$$

where $G_t$ is the Expected sum of future rewards.

---

The same goes for the Action-value function.

$$\begin{align}
q_*(s,a) &amp; = \sum_{s'}\sum_r p(s',r|s,a)[r + \gamma \sum_{a'} \pi_*(a'|s') q_*(s',a')] \\
       &amp; = \sum_{s'}\sum_r p(s',r|s,a)[r + \gamma \max_{a'} q_*(s',a')]
\end{align}$$

---

Let's say we have a policy $\pi_1$ that has a value function $v_{\pi_1}$. If we use $v_{\pi_1}$ to evaluate states but, instead of following $\pi_1$, we actually always select the actions that will take us to the future state $s'$ with highest $v_{\pi_1}(s')$, we will end up with a policy $\pi_2$ that is equal to or better than $\pi_1$.

---

$$\begin{align}
v_*(s) &amp; = \sum_a \pi_*(a|s) &amp; \sum_{s'}\sum_r p(s',r|s,a)[r + \gamma v_*(s')] \\
       &amp; = \max_a &amp; \sum_{s'}\sum_r p(s',r|s,a)[r + \gamma v_*(s')]
\end{align}$$
where $\pi_*$ is the Optimal policy.

The same goes for the Action-value function.

---

It's a function that dictates the probability the state will find itself in an arbitrary state $s'$ and the agent will receive reward $r$, given the current state the environment finds itself in, $s$, and the action chosen by the agent in $s$, depicted as $a$. It is usually denoted as $p(s',r|s,a)$.

Some properties of this function:

---

Policy evaluation is the task of finding the state-value function $v_{\pi}$, given the policy $\pi$. ^1b9b46

---
</code></pre></div></div> <h4 id="maximal-marginal-relevance-search">Maximal marginal relevance search</h4> <p>Plain similarity search has a drawback. It tends to recover chunks which are very similar or even identical, diminishing the overall amount of information present in the retrieved chunks.</p> <p>To solve this, LangChain provides a method called maximal marginal relevance search, which works by <em>“[…] finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.”</em> <a href="https://python.langchain.com/docs/modules/model_io/prompts/example_selector_types/mmr">[source]</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">retrieved_docs</span> <span class="o">=</span> <span class="n">vectordb</span><span class="p">.</span><span class="nf">max_marginal_relevance_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">retrieved_docs</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">doc</span><span class="p">.</span><span class="n">page_content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="sh">"</span><span class="se">\n</span><span class="s">---</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The action-value function represents the expected return from a given state after taking a specific action and later following a specific policy.

$$q_{\pi}(s,a)=\mathbb{E}_{\pi}[G_t|S_t=s,A_t=a]$$

where $G_t$ is the Expected sum of future rewards.
---
A value function maps states, or state-action pairs, to expected returns.

- State-value function
- Action-value function
---
A generalization of Sarsa which employs the n-step return for the action value function,

!n-step return#^205a30 ^68659e

This estimate is then used in the following update rule for the action-value of the state-action pair at time $t$.

$$Q_{t+n}(S_t, A_t) \doteq Q_{t+n-1}(S_t, A_t) + \alpha [G_{t:t+n} - \gamma^n Q_{t+n-1}(S_t, A_t)]$$ ^ca04db
---
- if the agent exploits without having a good estimate of the action-value function, it will most likely be locked in suboptimal behavior, not being able to gather information from unknown transitions which might bring it more return.
---
Some properties of this function:

It maps states and actions to states and rewards, so its cardinality is $$p:S \times R \times S \times A \to [0;1]$$

It is a probability, so the sum over all possible combinations of states and rewards must be one,
$$\sum_{s' \in S} \sum_{r \in R} p(s',r|s,a) = 1, \forall s \in S, a \in A(s)$$
---
# Factored value functions in cooperative multi-agent reinforcement learning

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/W_9kcQmaWjo?start=684" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

VDN was the first one and the one I used in my Doctorate.
---
- Exploitation: select the greedy action with relation to the action-value function.
- Exploration: select a non-greedy action.
---
Given the following MDP:

!Pasted image 20210523192818.png

The Bellman equation allows the value function to be expressed and solved as a system of linear equations: ^c06dd9

!Bellman equation for the state-value function#^a65ad4
---
</code></pre></div></div> <h3 id="llm-backed-retrieval">LLM-backed retrieval</h3> <p>Some retrieval techniques require an underlying language model to be performed. The LLM may be used to, e.g. summarize or make chunks more coherent before returning them.</p> <h4 id="instantiating-the-llm">Instantiating the LLM</h4> <p>The LLM I chose is <a href="https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca">Mistral-7B-OpenOrca</a>, provided by <a href="https://gpt4all.io/index.html">GPT4All</a>.</p> <ul> <li><a href="https://mistral.ai/news/announcing-mistral-7b/">Mistral 7B</a> is the best free and open 7 billion parameter LLM. It is also small enough to run on my GPU.</li> <li>The <a href="https://huggingface.co/datasets/Open-Orca/OpenOrca">OpenOrca dataset</a> is a conversation dataset.</li> <li>According to <a href="https://mistral.ai/product/">Mistral’s product website</a>, this model has an 8k context window, which we should consider when retrieving chunks for it to process.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !pip install gpt4all
# !pip install lark
# !wget https://gpt4all.io/models/gguf/mistral-7b-openorca.Q4_0.gguf -O models/my_little_llm.gguf
# !wget https://gpt4all.io/models/gguf/nous-hermes-llama2-13b.Q4_0.gguf -O models/my_little_llm.gguf
</span><span class="kn">from</span> <span class="n">langchain_community.llms.gpt4all</span> <span class="kn">import</span> <span class="n">GPT4All</span>

<span class="n">llm</span> <span class="o">=</span> <span class="nc">GPT4All</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">models/my_little_llm.gguf</span><span class="sh">"</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sh">"</span><span class="s">gpu</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llama.cpp: using Vulkan on NVIDIA GeForce GTX 1070
</code></pre></div></div> <h4 id="self-query-retrieval">Self-query retrieval</h4> <p>Self-query is a technique in which an LLM is specifically prompted to output a <em>structured query</em>. It also allows it to take document/chunk metadata into consideration, as long as we describe each attribute in the metadata with a textual description.</p> <p>Under the hood, self-query performs some pretty convoluted modifications to the original prompt and I advise you look at the documentation to understand what’s going on. <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query#constructing-from-scratch-with-lcel">[Source]</a></p> <p>As we have seen when inspecting our splits, we can see that our data includes metadata taken from the file properties of Obsidian documents. We will go ahead and described them as attributes for the self-query retriever.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.chains.query_constructor.base</span> <span class="kn">import</span> <span class="n">AttributeInfo</span>

<span class="n">metadata_field_info</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nc">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">source</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">The name of the Markdown file that contained the chunk. If you ignore the .md extension, it is the name of the article the chunk came from.</span><span class="sh">"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">string</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nc">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">aliases</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">Other names for the article the chunk came from, if any.</span><span class="sh">"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">string</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nc">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">tags</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">A series of comma-separated tags that categorize the article the chunk came from. When a tags starts with </span><span class="sh">'</span><span class="s">area</span><span class="sh">'</span><span class="s">, it denotes a broad area of knowledge. When it starts with </span><span class="sh">'</span><span class="s">project</span><span class="sh">'</span><span class="s">, it describes a specific project with beginning and end.</span><span class="sh">"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">string</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nc">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">authors</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">When the document summarizes a scientific paper, this attribute holds a comma-separated list of author names.</span><span class="sh">"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">string</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nc">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">When the document summarizes a scientific paper, this attribute contains the year of the publication.</span><span class="sh">"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">integer</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">]</span>
<span class="n">document_content_description</span> <span class="o">=</span> <span class="sh">"</span><span class="s">A collection of study notes in Markdown format written by a single author, mostly about artificial intelligence topics.</span><span class="sh">"</span>
</code></pre></div></div> <p>The self-query retriever can also be configured to use maximal marginal relevance search, as you can see in the <code class="language-plaintext highlighter-rouge">base_retriever</code> argument below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.retrievers.self_query.base</span> <span class="kn">import</span> <span class="n">SelfQueryRetriever</span>

<span class="n">retriever</span> <span class="o">=</span> <span class="n">SelfQueryRetriever</span><span class="p">.</span><span class="nf">from_llm</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
    <span class="n">vectorstore</span><span class="o">=</span><span class="n">vectordb</span><span class="p">,</span>
    <span class="n">document_contents</span><span class="o">=</span><span class="n">document_content_description</span><span class="p">,</span>
    <span class="n">metadata_field_info</span><span class="o">=</span><span class="n">metadata_field_info</span><span class="p">,</span>
    <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">mmr</span><span class="sh">"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">retriever</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Document(page_content='!Pasted image 20231129031306.png', metadata={'created': 1708307272.9665868, 'date': '2023-11-29 01:34', 'last_accessed': 1708307272.9699202, 'last_modified': 1708307272.9665868, 'path': '/home/dodo/Documents/Obsidian/Single linkage.md', 'source': 'Single linkage.md', 'tags': 'area/ai/ml/clustering'}),
 Document(page_content='!Pasted image 20230317051147.png', metadata={'created': 1680667926.0942817, 'date': '2023-03-17 04:33', 'last_accessed': 1708267663.323892, 'last_modified': 1680667926.0942817, 'path': '/home/dodo/Documents/Obsidian/Comparing feature vectors in NLP.md', 'source': 'Comparing feature vectors in NLP.md', 'tags': 'area/ai/nlp project/nlp-spec'}),
 Document(page_content='!Pasted image 20230325081439.png', metadata={'created': 1679742881.9000912, 'last_accessed': 1708267661.4972079, 'last_modified': 1679742881.9000912, 'path': '/home/dodo/Documents/Obsidian/Text cleaning.md', 'source': 'Text cleaning.md'}),
 Document(page_content='!_attachments/Pasted image 20210523185724.png', metadata={'created': 1680669713.8148472, 'date': '2023-04-05 01:41', 'last_accessed': 1708267662.710553, 'last_modified': 1680669713.8148472, 'path': '/home/dodo/Documents/Obsidian/Iterative policy evaluation.md', 'source': 'Iterative policy evaluation.md', 'tags': 'area/ai/rl project/rl-spec'})]
</code></pre></div></div> <p>As we can see, without more informative metadata (or better preprocessing of the text documents), the retrieved chunks are not very useful. It only retrieved chunks related to figures.</p> <h3 id="contextual-compression-retrieval">Contextual compression retrieval</h3> <p>As a final test on retrieval, we will implement a <em>“contextual compression retriever”</em>.</p> <p>From the <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression">LangChain documentation</a>:</p> <blockquote> <p>The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents and passes them through the Document Compressor. The Document Compressor takes a list of documents and shortens it by reducing the contents of documents or dropping documents altogether.</p> </blockquote> <p>In our case:</p> <ul> <li>The base retriever will be a maximal marginal similarity search.</li> <li>The compressor will be Mistral-7b-OpenOrca.</li> </ul> <p>Our hope is that the small, irrelevant chunks returned by the self-query retriever will be dropped and more relevant chunks will be summarized and returned.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.retrievers</span> <span class="kn">import</span> <span class="n">ContextualCompressionRetriever</span>
<span class="kn">from</span> <span class="n">langchain.retrievers.document_compressors</span> <span class="kn">import</span> <span class="n">LLMChainExtractor</span>

<span class="n">compressor</span> <span class="o">=</span> <span class="n">LLMChainExtractor</span><span class="p">.</span><span class="nf">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>
<span class="n">compression_retriever</span> <span class="o">=</span> <span class="nc">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span> <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">mmr</span><span class="sh">"</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compressed_docs</span> <span class="o">=</span> <span class="n">compression_retriever</span><span class="p">.</span><span class="nf">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="n">compressed_docs</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(
/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(
/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(
/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(





[Document(page_content='The action-value function represents the expected return from a given state after taking a specific action and later following a specific policy.', metadata={'created': 1680669936.852964, 'date': '2023-04-05 01:45', 'last_accessed': 1708267660.0105264, 'last_modified': 1680669936.852964, 'path': '/home/dodo/Documents/Obsidian/Action-value function.md', 'source': 'Action-value function.md', 'tags': 'area/ai/rl project/rl-spec'}),
 Document(page_content='Action-value function', metadata={'created': 1680669672.8131003, 'date': '2023-04-05 01:41', 'last_accessed': 1708267659.7238567, 'last_modified': 1680669672.8131003, 'path': '/home/dodo/Documents/Obsidian/Value functions.md', 'source': 'Value functions.md', 'tags': 'area/ai/rl project/rl-spec'}),
 Document(page_content='*NO_OUTPUT*\n\nThe definition of the action value function is not mentioned in this context.', metadata={'created': 1633628586.5949209, 'date': '2021-03-02 23:01', 'last_accessed': 1708267661.2005382, 'last_modified': 1632030179.7187316, 'path': '/home/dodo/Documents/Obsidian/Factored value functions in cooperative multi-agent reinforcement learning.md', 'source': 'Factored value functions in cooperative multi-agent reinforcement learning.md', 'tags': 'None'}),
 Document(page_content='Action-Value Function Definition: Not mentioned in the context.', metadata={'created': 1680669515.4254303, 'date': '2023-04-05 01:38', 'last_accessed': 1708267661.453874, 'last_modified': 1680669515.4254303, 'path': '/home/dodo/Documents/Obsidian/Exploration-exploitation tradeoff.md', 'source': 'Exploration-exploitation tradeoff.md', 'tags': 'area/ai/rl project/rl-spec'})]
</code></pre></div></div> <p>These results seem much better than the previous ones, but they are still just a collection of chunks. When interacting with LLMs and chatbots in general, we expect a more direct response.</p> <h2 id="question-answering-using-llms-and-rag">Question-answering using LLMs and RAG</h2> <p>In this example, we will perform retrieval augmented generation for question-answering in an Obsidian document database.</p> <p>To summarize what we already have for this step:</p> <ol> <li>Our documents have been loaded and preprocessed.</li> <li>Chunks have been split from the documents, embedded and stored in the vector store.</li> <li>An LLM has been successfully loaded into memory.</li> </ol> <h3 id="plain-retrieval-qa">Plain retrieval Q&amp;A</h3> <p>This method of Q&amp;A uses the prompt to find relevant chunks in the vector store. These chunks are called the <em>context</em> of the prompt and they are concatenated to the prompt, which is then passed directly to the LLM.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.chains</span> <span class="kn">import</span> <span class="n">RetrievalQA</span>

<span class="n">qa_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">mmr</span><span class="sh">"</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <p>We can see which arguments the chain expects by inspecting the input_keys <code class="language-plaintext highlighter-rouge">list</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">qa_chain</span><span class="p">.</span><span class="n">input_keys</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['query']
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span> <span class="o">=</span> <span class="nf">qa_chain</span><span class="p">({</span><span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">:</span> <span class="n">question</span><span class="p">})</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/dodo/.anaconda3/envs/langsidian/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.
  warn_deprecated(
</code></pre></div></div> <p>The result of prompting the overall system can be seen below. If you remember the definition of the action-value function <a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#value-functions">[source]</a>, our Q&amp;A bot has pretty much nailed it!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'query': 'What is the definition of the action value function?',
 'result': ' The action-value function represents the expected return from a given state after taking a specific action and later following a specific policy.'}
</code></pre></div></div> <p>Under the hood, the <code class="language-plaintext highlighter-rouge">RetrievalQA</code> object uses a prompt template into which it replaces the context and the question before sending the full text prompt to the LLM. We can see it by inspecting the object’s graph.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">qa_chain</span><span class="p">.</span><span class="nf">get_graph</span><span class="p">().</span><span class="n">nodes</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'7eac904b44594e20852d8f0519ef0c3e': Node(id='7eac904b44594e20852d8f0519ef0c3e', data=&lt;class 'pydantic.v1.main.ChainInput'&gt;),
 '8e824ec8c0654d0db3b83b56bd66b619': Node(id='8e824ec8c0654d0db3b83b56bd66b619', data=RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template="Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n{context}\n\nQuestion: {question}\nHelpful Answer:"), llm=GPT4All(model='models/my_little_llm.gguf', device='gpu', client=&lt;gpt4all.gpt4all.GPT4All object at 0x776da5594320&gt;)), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=&lt;langchain_community.vectorstores.chroma.Chroma object at 0x776cf1b45be0&gt;, search_type='mmr'))),
 '4b55a6602f9542fe8d583ac66c6ae722': Node(id='4b55a6602f9542fe8d583ac66c6ae722', data=&lt;class 'pydantic.v1.main.ChainOutput'&gt;)}
</code></pre></div></div> <h3 id="retrieval-qa-with-custom-prompt-template">Retrieval Q&amp;A with custom prompt template</h3> <p>The example below shows how to edit the prompt template used by the chain, albeit, in this case, with limited success. This is due to the limited performance of the LLM being used.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># Build prompt
</span><span class="n">template</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">Use the following pieces of context to answer the question at the end. If you don</span><span class="sh">'</span><span class="s">t know the answer, just say that you don</span><span class="sh">'</span><span class="s">t know, don</span><span class="sh">'</span><span class="s">t try to make up an answer. At the end of the response, say </span><span class="se">\"</span><span class="s">over and out</span><span class="se">\"</span><span class="s">.
{context}
Question: {question}
Helpful Answer:</span><span class="sh">"""</span>
<span class="n">qa_chain_prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">.</span><span class="nf">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="c1"># Run chain
</span><span class="n">qa_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">mmr</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">return_source_documents</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">chain_type_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">prompt</span><span class="sh">"</span><span class="p">:</span> <span class="n">qa_chain_prompt</span><span class="p">},</span>
<span class="p">)</span>
</code></pre></div></div> <p>Let’s ask a few questions to our Q&amp;A bot and render the output as some nice Markdown.</p> <p>Note that we can also output the documents that were retrieved during RAG and used to compose the answer, but that would pollute the output too much, so I left it commented out.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Markdown</span>

<span class="n">questions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">Given me the equation for the action value function update.</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">What is the overall architecture of the Deep Q-Networks?</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">What is the difference between causal language modelling and masked language modelling?</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">What is zero-shot learning?</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Explain to me the concept of bucketing in RNNs.</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">What is a named entity in the concept of NLP?</span><span class="sh">"</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">questions</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nf">qa_chain</span><span class="p">({</span><span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">:</span> <span class="n">q</span><span class="p">})</span>

    <span class="nf">display</span><span class="p">(</span><span class="nc">Markdown</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">**Question: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">]</span><span class="si">}</span><span class="s">**</span><span class="se">\n\n</span><span class="s"> Answer: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">))</span>
    <span class="c1"># source_docs = "\n\n".join(d.page_content for d in result["source_documents"])
</span>    <span class="c1"># print(
</span>    <span class="c1">#     f"Source documents\n\n{source_docs}"
</span>    <span class="c1"># )
</span></code></pre></div></div> <p><strong>Question: Given me the equation for the action value function update.</strong></p> <p>Answer: The equation for the action-value function update is given by:</p> \[q_{\pi}(s,a) = R(s,a) + \&lt;dummy32001&gt;{ \gamma V_\pi (s') | s' \in S'}\] <p>where $R(s,a)$ is the reward received when taking action a in state s and $\gamma$ is the discount factor.</p> <p><strong>Question: What is the overall architecture of the Deep Q-Networks?</strong></p> <p>Answer: The overall architecture of a Deep Q-Network (DQN) consists of an input layer, multiple hidden layers with nonlinear activation functions, and an output layer. It uses experience replay to store past experiences for training purposes, and employs target networks to stabilize the learning process. over and out</p> <p><strong>Question: What is the difference between causal language modelling and masked language modelling?</strong></p> <p>Answer: Causal language modeling refers to a method where the model predicts the next token in a sequence based on the previous tokens. In contrast, masked language modeling involves randomly masking some tokens during training time and then trains the model to reconstruct the original text by predicting the masked tokens.</p> <p><strong>Question: What is zero-shot learning?</strong></p> <p>Answer: Zero-shot learning refers to a model’s ability to perform new tasks without being explicitly trained on those specific tasks or examples. In the context of large language models, it means that an AI can execute new tasks without needing any explicit training data for those tasks.</p> <p><strong>Question: Explain to me the concept of bucketing in RNNs.</strong></p> <p>Answer: Bucketing in RNNs refers to grouping or organizing input sequences into fixed-sized groups, called “buckets”, before processing them with an RNN model. This technique helps improve training efficiency and reduce padding by ensuring that each bucket contains a sufficient amount of randomness and variability while preventing it from being too large so as not to introduce excessive padding.</p> <p><strong>Question: What is a named entity in the concept of NLP?</strong></p> <p>Answer: In the context of Natural Language Processing (NLP), a named entity refers to a real-world object that can be denoted with a proper name. Examples are a person, location, organization, product. It can be abstract or have a physical existence.</p> <p>In some answers, the model has actually followed the instructions from the new prompt, but we need a much more powerful LLM, or the employment of techniques such as few-shot learning, to get better instruction-following results.</p> <h2 id="conclusions">Conclusions</h2> <p>This notebook presented a proof-of-concept on how to create a question-answering bot powered by an LLM and with knowledge extracted from actual documents, more specifically, a collection of notes from Obsidian.</p> <p>We were able to run all experiments locally, using a 7th gen i7, an NVIDIA GTX 1070 and 32 GBs of RAM.</p> <p>We were also introduced to many concepts on the road to building this Q&amp;A bot, such as:</p> <ol> <li>Document loading</li> <li>Text data cleaning using regex</li> <li>Splitting of Markdown documents into text chunks</li> <li>Sentence embeddings</li> <li>Vector stores</li> <li>Similarity search using cosine similarity between embedding vectors</li> <li>maximal marginal relevance search</li> <li>Self-query retrieval</li> <li>Contextual compression retrieval</li> <li>Question-answering with retrieval augmented generation</li> <li>Question-answering with retrieval augmented generation and custom templates</li> </ol> <p>In future work, let’s build an actual chatbot that remembers previous answers and can keep up a lengthier conversation.</p>]]></content><author><name></name></author><category term="llms"/><category term="nlp"/><category term="python"/><category term="neural-networks"/><summary type="html"><![CDATA[This notebook presents a proof-of-concept on how to create a question-answering bot powered by an LLM and with knowledge extracted from actual documents, more specifically, a collection of notes from Obsidian.]]></summary></entry><entry><title type="html">Configuring Visual Studio Code for LaTeX</title><link href="https://douglasrizzo.github.io/blog/2021/06/configuring-vscode-for-latex/" rel="alternate" type="text/html" title="Configuring Visual Studio Code for LaTeX"/><published>2021-06-11T00:00:00+00:00</published><updated>2021-06-11T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2021/06/configuring-vscode-for-latex</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2021/06/configuring-vscode-for-latex/"><![CDATA[<p><a href="https://code.visualstudio.com/">VS Code</a> has very poor LaTeX support out-of-the-box. Here I list useful extensions and other software that will transform VS Code into a much more power LaTeX editor. They also do not conflict with each other, which is great.</p> <h2 id="getting-it-out-of-the-way-latex-workshop">Getting it out of the way: LaTeX Workshop</h2> <p>While I have used LaTeX Workshop for a long time, I started experiencing a few issues with it that, over time, got really annoying. The main issue is simply <a href="https://github.com/James-Yu/LaTeX-Workshop/issues/1193">the Enter key not working</a>, which was then replaced by <a href="https://github.com/James-Yu/LaTeX-Workshop/issues/903">a substantial delay between pressing the Enter key and actually inserting a new line character</a>. Fixing one apparently introduced the other, so, after many tries, I just gave up on LaTeX Workshop.</p> <h2 id="what-i-use-now">What I use now</h2> <ul> <li>Code completion: <a href="https://marketplace.visualstudio.com/items?itemName=efoerster.texlab">TeXLab VS Code extension</a>. It depends on another program called <a href="https://texlab.netlify.app/">TeXLab</a>, but the extension usually installs it automatically.</li> <li>Syntax highlighting <a href="https://marketplace.visualstudio.com/items?itemName=vomout.latex-syntax">Rich LaTeX syntax highlighting (for use with Texlab)</a>.</li> <li>Grammar checking: <a href="https://marketplace.visualstudio.com/items?itemName=valentjn.vscode-ltex">LTeX</a>. Be sure to check the <a href="https://valentjn.github.io/vscode-ltex/docs/settings.html">documentation</a> to learn how to configure the extension to check different languages.</li> <li>PDF visualization: If TeXLab has not worked out for you when opening PDF files, you can use an extension called <a href="https://marketplace.visualstudio.com/items?itemName=sandcastle.vscode-open">Open</a>, which opens a file in its default application.</li> </ul> <p>The TeXLab VS Code extension also provides other useful features, as long as the appropriate programs are installed and in your Linux <code class="language-plaintext highlighter-rouge">PATH</code> (or whatever the equivalent in Mac/Windows is). These assorted programs are usually included in TeX Live, but can be installed through your distribution’s package manager, if you are on Linux.</p> <ul> <li>LaTeX formatting (with <code class="language-plaintext highlighter-rouge">latexindent</code>)</li> <li>Compilation via the F5 shortcut (with <code class="language-plaintext highlighter-rouge">latexmk</code>)</li> <li>Linting (with <code class="language-plaintext highlighter-rouge">chktex</code>)</li> <li>Opening the final PDF file with a shortcut (through the <a href="https://github.com/latex-lsp/texlab/blob/master/docs/previewing.md">forward search</a> option)</li> </ul>]]></content><author><name></name></author><category term="vscode"/><category term="tutorial"/><summary type="html"><![CDATA[VS Code has very poor LaTeX support out-of-the-box. Here I list useful extensions and other software that will transform VS Code into a much more power LaTeX editor. They also do not conflict with each other, which is great.]]></summary></entry><entry><title type="html">Resources to self-study mathematics for machine learning</title><link href="https://douglasrizzo.github.io/blog/2021/06/mathematics-self-study/" rel="alternate" type="text/html" title="Resources to self-study mathematics for machine learning"/><published>2021-06-11T00:00:00+00:00</published><updated>2021-06-11T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2021/06/mathematics-self-study</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2021/06/mathematics-self-study/"><![CDATA[<blockquote> <p>Two plus two is four, minus one, that’s three. Quick maths.</p> <p><a href="https://youtu.be/3M_5oYU-IsU?t=63">Michael Dapaah</a></p> </blockquote> <ul> <li><a href="#introduction">Introduction</a></li> <li><a href="#study-areas">Study areas</a> <ul> <li><a href="#algebra-and-pre-calculus">Algebra and pre-calculus</a></li> <li><a href="#calculus">Calculus</a></li> <li><a href="#linear-algebra">Linear Algebra</a> <ul> <li><a href="#advanced-linear-algebra">Advanced Linear Algebra</a></li> </ul> </li> </ul> </li> <li><a href="#software-and-apps">Software and apps</a></li> <li><a href="#online-communities">Online communities</a></li> <li><a href="#my-failures">My failures</a></li> <li><a href="#final-thoughts">Final thoughts</a></li> <li><a href="#more-resources-and-moving-forward">More resources and moving forward</a></li> </ul> <h2 id="introduction">Introduction</h2> <p>When I started my PhD, I didn’t know at first if my research would take me in a path whose foundations I was comfortable with, such as algorithms, logic and other discrete areas, or if fate would take me towards the more mathematical path. As I started to get really interested in the applications of neural networks for reinforcement learning, I realized little by little that I would not only need to remember all the mathematics I had learned before in my life, but also learn and get comfortable with some new stuff.</p> <p>In this article, I go over:</p> <ul> <li>what topics I’ve been studying;</li> <li>in which order I study them;</li> <li>what material worked for me;</li> <li>where to find them online (the free ones, at least);</li> <li>which software, online services and apps I use;</li> <li>where to find online communities to post questions and answers and to study together in real time;</li> <li>where I failed in my studies;</li> <li>some final tips;</li> <li>links to more resources.</li> </ul> <h2 id="study-areas">Study areas</h2> <h3 id="algebra-and-pre-calculus">Algebra and pre-calculus</h3> <p>I recommend the <a href="https://jamesbrennan.org/algebra/">free algebra book by James Brennan</a> and the <a href="https://www.stitz-zeager.com/">free precalculus book by Stitz and Zaeger</a>, which I found out about in the very helpful <a href="https://reddit.com/r/learnmath">/r/learnmath</a> subreddit. My recommendation would be to evaluate which topics you remember and just skim over them, while giving yourself more time over the stuff you don’t remember or have never learned.</p> <p>Personally, I made a lot of progress by just following both books until I felt I was comfortable with my knowledge. I tried not to skip anything, but I also felt like I could work fast as I had already learned most of this stuff before.</p> <h3 id="calculus">Calculus</h3> <p>To study calculus, I used the <a href="https://stewartcalculus.com/media/16_home.php">books by Stewart</a>, 8th edition. I knew I was prepared to start calculus when I had studied enough algebra to fulfill the prerequisites at the start of the book. I also worked through the two review lists available in Stewart’s website <a href="https://stewartcalculus.com/data/CALCULUS_8E/upfiles/6e_reviewofalgebra.pdf">[1]</a> <a href="https://stewartcalculus.com/data/CALCULUS_8E/upfiles/6e_reviewofanalgeom.pdf">[2]</a>. Those lists helped me to prioritize what I needed to focus on my aforementioned precalculus quest.</p> <h3 id="linear-algebra">Linear Algebra</h3> <p>I decided to start studying linear algebra alongside calculus. I had an easier time with linear algebra as I already had some familiarity with matrix operations, not only because I was already working with neural networks for quite some time, but I also implemented <a href="douglasrizzo.github.io/matrix">my own matrix class in C++</a> at one point.</p> <p>I started with a <a href="https://www.google.com.br/books/edition/Algebra_linear/M8CNGwAACAAJ?hl=en">Brazilian undergrad text book from 1986</a>, but also searched many concepts on YouTube, since I did not get the intuition behind some of them. I ended up ditching the book after getting acquainted with <a href="https://www.amazon.com/gp/product/B019EB9S4O/">Larson’s book</a>, which presented the material in a much nore contemporary fashion.</p> <h4 id="advanced-linear-algebra">Advanced Linear Algebra</h4> <p>I haven’t gotten here yet, but after learning all the basic stuff about matrices, vector spaces, linear transforms and eigenthingies, I was recommended the book <a href="https://www.amazon.com/Linear-Algebra-Right-Sheldon-Axler/dp/3319110799/">Linear Algebra Done Right</a>, by Sheldon Axler to move on to more advanced stuff.</p> <h2 id="software-and-apps">Software and apps</h2> <ul> <li><strong>Solvers:</strong> These are services that do things like simplifying expressions, solving for $x$, finding derivatives, minima and maxima values of functions and so on. You name it, they do it. Just be careful that, sometimes, the answers are either more convoluted than they need to be, or simpler than you’d want them to be. <ul> <li><a href="https://www.wolframalpha.com/">Wolfram Alpha</a> is in this category. Instead of paying for a subscription to the website, a cheaper solution is to buy <a href="https://play.google.com/store/apps/details?id=com.wolfram.android.alpha">the smartphone app</a>, which is a one-time purchase that gives you the coveted “step-by-step solution” functionality.</li> <li>A free alternative which is equally impressive is <a href="https://math.microsoft.com/">Microsoft Math Solver</a>, which also has a more user-friendly <a href="https://play.google.com/store/apps/details?id=com.microsoft.math">mobile app</a>.</li> </ul> </li> <li><strong>Graphical calculators:</strong> you’re gonna need these ones often, to visualize functions, derivatives, systems of equations etc. I recommend the Desmos Graphical Calculator, a very famous graphical calculator, which is freely available <a href="https://www.desmos.com/calculator">online</a> and as <a href="https://play.google.com/store/apps/details?id=com.desmos.calculator">an app</a>. It only works in two dimensions, I don’t really know if there is anything fancier than that.</li> <li><strong>Actual calculators:</strong> On Linux, I use <a href="http://speedcrunch.org/">SpeedCrunch</a> for <a href="https://youtu.be/3M_5oYU-IsU?t=63">quick maths</a> or <a href="https://qalculate.github.io/">Qalculate!</a> for more symbolic stuff (with fractions, units of measurement etc). On mobile, I’d recommend <a href="https://play.google.com/store/apps/details?id=com.desmos.scientific">Desmos Scientific Calculator</a>. I know some people like to use “calculator simulators” but I haven’t had the need for that.</li> <li><strong>Linear algebra special:</strong> instead on depending on MATLAB or some other obnoxious monolithic proprietary software, you can represent systems of linear equations as matrices in Python using <a href="https://numpy.org/">NumPy</a> and manipulate/solve them using <a href="https://numpy.org/devdocs/reference/routines.linalg.html"><code class="language-plaintext highlighter-rouge">numpy.linalg</code></a>. You can load <code class="language-plaintext highlighter-rouge">.mat</code> files into Python variables using <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html">SciPy’s <code class="language-plaintext highlighter-rouge">loadmat</code> function</a>.</li> </ul> <h2 id="online-communities">Online communities</h2> <p>It came a point in which I started having the kind of questions that I couldn’t quite google my way to the answer. When I started to look for a place to post my questions, I found the extremely active and welcoming <a href="https://reddit.com/r/learnmath">/r/learnmath</a> subreddit. The people there are really nice and welcoming of noobs and they are a lot less strict than other sites, such as the Math Stack Exchange.</p> <p>Another place I suggest people to look are Discord servers, where people gather to talk about homework. An example is <a href="https://discord.gg/USVc7XX">Homework Help</a>. There are also study servers on Discord in which people can keep you company in mute video calls. I highly recommend the <a href="https://discord.gg/s9tEhQPw8A">Study Lions</a>, but there are others.</p> <p>Overall, my advice with regards to communities is to both <strong>seek and provide help</strong>. Seeing people ask questions to which I knew the answer to made me realize how much I had actually learned in my journey, which really motivated me. Also, I could help a random stranger online, which is nice.</p> <h2 id="my-failures">My failures</h2> <p>Humble time. Since I didn’t know where to start, I decided to enroll in online university courses and let the lectures guide me. I had had a great experience with Coursera and the machine learning course by Andrew Ng, so I thought I’d have an equally positive experience with Coursera’s math courses<sup id="fnref:calc-courses" role="doc-noteref"><a href="#fn:calc-courses" class="footnote" rel="footnote">1</a></sup>.</p> <p>However, unlike the previous courses I took, I couldn’t watch the lectures or complete the assignments before or after the correct dates, which really frustrated me.</p> <p>Another problem I faced was that I just couldn’t follow the professors in some of the lectures. Sometimes, the exercises after a lesson seemed to have nothing to do with the lesson itself. Since I had no other material to follow, I felt stuck in some lessons and couldn’t meet the deadlines.</p> <h2 id="final-thoughts">Final thoughts</h2> <ul> <li> <p><strong>Don’t force it:</strong> Studying mathematics ended up becoming a hobby of mine, one that I could spend an entire day doing, after I had started. There were days that I would eat up over 20 pages of a book, a pretty decent number if you ask me, since I’d be able to end a 400 page book in 20 days (not that I did that). My main problem was, and still is, consistency. I can’t really do the whole “study everyday for 30 minutes” thing. I usually studied for the whole day, twice a week.</p> <p>I’ll admit I did not study any of the books from cover to cover and I am still working through them, but I never felt hindered or delayed by the method I chose to study mathematics. My only limitations are time, since I have other responsibilities, and motivation.</p> </li> <li> <p><strong>Find the format that is best for you:</strong> since I did very well in online AI courses <a href="https://www.coursera.org/verify/BJWU9J3F9J4X">[1]</a> <a href="http://coursera.org/verify/specialization/7YLWXWJ5GUKJ">[2]</a>, I thought the same would be true for online math courses. However, when it came to mathematics, I felt like books were a much better medium, as they present the material in both a rigorous and linear fashion, delving into the theory and definitions and following up with lots of examples and exercises which could mostly be completed with the material presented right before. Text books are also good when I just wanted to review some old algebra, in which case I am able to quicly skip to whatever concept I am interested in, while videos would be much harder to sift through.</p> </li> <li> <p><strong>YouTube is your friend:</strong> I tend to forget basic stuff very often, such as how to complete the square, trigonometric identities (<a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities">there are lots of them</a>) or the binomial theorem. In these cases, looking up a YouTube video is much faster than searching for what you need in books. Math videos usually go directly to the point and you don’t waste any time.</p> </li> </ul> <h2 id="more-resources-and-moving-forward">More resources and moving forward</h2> <p>This video my the Math Sorcerer lists books from every area of Mathematics, starting from basic logic and algebra and going all the way up to the crazy stuff.</p> <iframe width="560" height="315" src="https://www.youtube.com/embed/pTnEG_WGd2Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> <p>This video by Aleph 0 has some book recommendations for undergraduate level courses in pure mathematics, with accompanying video lectures on YouTube.</p> <iframe width="560" height="315" src="https://www.youtube.com/embed/fo-alw2q-BU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> <hr/> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:calc-courses" role="doc-endnote"> <p>I enrolled in the UC Irvine precalculus course (which is not available on Coursera anymore, but can be found <a href="https://www.math.uci.edu/node/22608">here</a>) and later, in the University of Ohio calculus course (which also is not available anymore, but a few pointers to where the material is currently available are <a href="https://mooculus.osu.edu/lectures">[link]</a> <a href="https://www.youtube.com/user/kisonecat/playlists">[link]</a> <a href="https://www.coursera.org/instructor/jimfowler">[link]</a>). <a href="#fnref:calc-courses" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="mathematics"/><category term="self-study"/><category term="machine-learning"/><summary type="html"><![CDATA[Two plus two is four, minus one, that’s three. Quick maths. Michael Dapaah]]></summary></entry><entry><title type="html">Zotero tips and tricks</title><link href="https://douglasrizzo.github.io/blog/2021/06/zotero-tips/" rel="alternate" type="text/html" title="Zotero tips and tricks"/><published>2021-06-11T00:00:00+00:00</published><updated>2021-06-11T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2021/06/zotero-tips</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2021/06/zotero-tips/"><![CDATA[<p><strong>tl;dr:</strong> <a href="https://www.zotero.org/"><strong>Zotero</strong></a> is great but it lacks good cloud sync support and a way to make a giant .bib file available for referencing. You can get the first with the <a href="http://zotfile.com/"><strong>Zotfile</strong></a> addon, pointing its PDF directory somewhere inside your cloud sync directory. You can get the second with the <a href="https://retorque.re/zotero-better-bibtex/"><strong>Better BibTeX</strong></a> addon, by exporting a <code class="language-plaintext highlighter-rouge">.bib</code> file which is always kept updated.</p> <h2 id="background">Background</h2> <p><a href="https://www.zotero.org/"><strong>Zotero</strong></a> is a great reference manager that has incorporated lots of much needed features along the years. Two things that I feel Zotero is still missing is</p> <ul> <li>good cloud sync support, so you can keep as many PDF files in your libraries without going over the measly 300 MB quota it gives;</li> <li>a central <code class="language-plaintext highlighter-rouge">.bib</code> file which can be referenced in all my projects.</li> </ul> <p>Here, I teach you how to circumvent these problems with two addons.</p> <h2 id="cloud-sync-with-zotfile">Cloud sync with Zotfile</h2> <p><a href="http://zotfile.com/"><strong>Zotfile</strong></a> is an addon that helps in managing PDF files inside Zotero. It allows for automatic and batch moving and renaming of file attachments.</p> <p>In order to sync all your PDF files among multiple computers, you can point Zotfile’s “PDF directory” setting into a folder inside your cloud sync service of choice (Mega, Dropbox, Google Drive, OneDrive etc.) and configure the addon to automatically move all new attachments to this folder. Zotero will then only keep links to these files in its database and will synchronize only these links, while the files themselves will be synchronized by your cloud sync application.</p> <h2 id="central-up-to-date-bib-database-with-better-bibtex">Central up-to-date bib database with Better BibTeX</h2> <p><a href="https://www.jabref.org/"><strong>JabRef</strong></a> introduced me to the as-of-yet unknown habit of keeping a single giant <code class="language-plaintext highlighter-rouge">.bib</code> file, which I would just link all my papers to and use the autocomplete function of my TeX editor of choice to search for entry keys.</p> <p>To emulate this behavior in Zotero, there is an addon called <a href="https://retorque.re/zotero-better-bibtex/"><strong>Better Bibtex</strong></a>. It allows me to export my entire library into a <code class="language-plaintext highlighter-rouge">.bib</code> file, which is then kept updated as I change information in my Zotero library. I actually kept two <code class="language-plaintext highlighter-rouge">.bib</code> files, one in BibTeX format for all my papers, and the other in BibLaTeX format, for my thesis.</p>]]></content><author><name></name></author><category term="zotero"/><category term="tutorial"/><summary type="html"><![CDATA[tl;dr: Zotero is great but it lacks good cloud sync support and a way to make a giant .bib file available for referencing. You can get the first with the Zotfile addon, pointing its PDF directory somewhere inside your cloud sync directory. You can get the second with the Better BibTeX addon, by exporting a .bib file which is always kept updated.]]></summary></entry><entry><title type="html">Detecting soccer balls with reduced neural networks</title><link href="https://douglasrizzo.github.io/blog/2021/02/detecting-soccer-balls-with-reduced-neural-networks/" rel="alternate" type="text/html" title="Detecting soccer balls with reduced neural networks"/><published>2021-02-21T00:00:00+00:00</published><updated>2021-02-21T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2021/02/detecting-soccer-balls-with-reduced-neural-networks</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2021/02/detecting-soccer-balls-with-reduced-neural-networks/"><![CDATA[<p>I was fortunate to have <a href="https://link.springer.com/article/10.1007/s10846-021-01336-y">published a paper</a> in the Journal of Intelligent &amp; Robotic Systems. While its <a href="https://arxiv.org/abs/2009.13684">preprint on arxiv</a> will remain there, I am allowed to host the post-review, pre-published version, which was greatly expanded, on my personal website . ou can find it below.</p> <iframe title="The Paper" width="100%" src="/files/jint2021-aam.pdf" height="1015"></iframe>]]></content><author><name></name></author><category term="object-detection"/><category term="neural-networks"/><category term="research-paper"/><summary type="html"><![CDATA[I was fortunate to have published a paper in the Journal of Intelligent &amp; Robotic Systems. While its preprint on arxiv will remain there, I am allowed to host the post-review, pre-published version, which was greatly expanded, on my personal website . ou can find it below.]]></summary></entry><entry><title type="html">Razões para deep reinforcement learning não funcionar</title><link href="https://douglasrizzo.github.io/blog/2021/02/razoes-para-deep-reinforcement-learning-nao-funcionar/" rel="alternate" type="text/html" title="Razões para deep reinforcement learning não funcionar"/><published>2021-02-19T00:00:00+00:00</published><updated>2021-02-19T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2021/02/razoes-para-deep-reinforcement-learning-nao-funcionar</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2021/02/razoes-para-deep-reinforcement-learning-nao-funcionar/"><![CDATA[<p>Essa é uma compilação de textos que eu encontrei na internet em momentos de frustração com meu trabalho. Eu os resumi e traduzi para compartilhar com as pessoas sempre que me perguntarem porque trabalhar com DRL é uma desgraça.</p> <ul> <li><a href="#comentários-do-karpathy">Comentários do Karpathy</a></li> <li><a href="#texto-lessons-learned-reproducing-a-deep-reinforcement-learning-paper">Texto: Lessons Learned Reproducing a Deep Reinforcement Learning Paper</a></li> <li><a href="#texto-deep-reinforcement-learning-doesnt-work-yet">Texto: Deep Reinforcement Learning Doesn’t Work Yet</a></li> </ul> <h2 id="comentários-do-karpathy">Comentários do Karpathy</h2> <p>O trecho abaixo é um comentário do Andrej Karpathy, da Tesla, <a href="https://news.ycombinator.com/item?id=13519044">neste link</a>.</p> <blockquote> <p>If it makes you feel any better, I’ve been doing this for a while and it took me last ~6 weeks to get a from-scratch policy gradients implementation to work 50% of the time on a bunch of RL problems. And I also have a GPU cluster available to me, and a number of friends I get lunch with every day who’ve been in the area for the last few years. Also, what we know about good CNN design from supervised learning land doesn’t seem to apply to reinforcement learning land, because you’re mostly bottlenecked by credit assignment / supervision bitrate, not by a lack of a powerful representation. Your ResNets, batchnorms, or very deep networks have no power here. SL wants to work. Even if you screw something up you’ll usually get something non-random back. RL must be forced to work. If you screw something up or don’t tune something well enough you’re exceedingly likely to get a policy that is even worse than random. And even if it’s all well tuned you’ll get a bad policy 30% of the time, just because. Long story short your failure is more due to the difficulty of deep RL, and much less due to the difficulty of “designing neural networks”.</p> </blockquote> <h2 id="texto-lessons-learned-reproducing-a-deep-reinforcement-learning-paper">Texto: Lessons Learned Reproducing a Deep Reinforcement Learning Paper</h2> <p>Fonte: <a href="http://amid.fish/reproducing-deep-rl">http://amid.fish/reproducing-deep-rl</a></p> <ol> <li> <p>Ao trabalhar com métodos programados no computador, nós frequentemente nos deparamos com problemas cuja solução não é óbvia. Quando o método não necessita de treinamento, é mais rápido e fácil ter várias ideias do que pode solucionar um problema e testar tudo em segundos do que realmente pensar na origem do problema. No caso de um algoritmo de RL, cada novo teste leva um ou mais dias, então é necessário pensar no problema para selecionar a solução mais provável, ou encontrar uma solução melhor, mesmo que não seja óbvia.</p> </li> <li> <p>Ao reproduzir o artigo de outra pessoa:</p> <ul> <li><strong>O que você aprende:</strong> como fazer um método de DRL funcionar, melhorando nossas habilidades de <em>RL engineers</em>.</li> <li>O que você pensa que vai aprender, <strong>mas não aprende:</strong> a surgir com novas ideias relevantes de pesquisa. Isso é melhor feito através da leitura crítica de outros artigos e do conhecimento de vários termos-chave da área.</li> </ul> </li> <li> <p>Algumas dicas que o autor tentou martelar nos leitores:</p> <ul> <li>se você vai usar um método de RL, tente não implementá-lo, LOL</li> <li>tente medir tudo o que é possível durante o treinamento. Não só métricas como recompensa ou erro da rede, mas outras métricas indiretas de sucesso</li> <li>escrever um diário dos experimentos para se lembrar do que você já tentou</li> </ul> </li> <li> <p>Outro ponto interessante do relato. O autor pensou que iria levar 3 meses pra terminar a reprodução do paper, mas levou <strong>8 meses</strong>. A maior parte do tempo é desprendida fazendo o algoritmo funcionar num exemplo simples. Depois, a demora está em instrumentar testes. Seguem abaixo os tempos que o autor demorou para:</p> <ul> <li>implementar a primeira versão do método (30 horas)</li> <li>fazer ele funcionar num exemplo básico (110 horas)</li> <li>fazer ele funcionar num exemplo novo (10 horas) e finalmente</li> <li>conseguir rodar testes consistentes (60 horas).</li> </ul> </li> </ol> <h2 id="texto-deep-reinforcement-learning-doesnt-work-yet">Texto: Deep Reinforcement Learning Doesn’t Work Yet</h2> <p>Fonte: https://www.alexirpan.com/2018/02/14/rl-hard.html</p> <p>Esse artigo lista diversos motivos pra métodos de DRL não funcionarem.</p> <ul> <li><em>ineficiência de amostras:</em> necessários milhões de exemplos pro método aprender</li> <li><em>nunca é o método mais eficiente:</em> métodos especializados pra cada problema quase sempre têm resultados melhores do que DRL: e.g., algoritmos de controle para robôs humanoides</li> <li><em>criação da função de recompensa:</em> precisa ser feita por uma pessoa e é difícil criar uma função que guia o agente de maneira óbvia para o objetivo, sem ser esparsa (+1 por vencer)</li> <li><em>retorno esperado pode ter máximos locais:</em> mesmo que o código esteja correto, o agente pode convergit para comportamentos inesperados, necessitando reiniciar o treinamento todo.</li> <li><em>agente aprende por overfitting:</em> difícil realizar transferência do que é aprendido para outro ambiente ou para uma pequena mudança no mesmo ambiente</li> <li><em>sensibilidade a inícios aleatórios:</em> o gráfico abaixo é um exemplo de treinar um algoritmo de DRL a equilibrar o pêndulo invertido várias vezes. Só funcionou 70% das vezes.</li> </ul> <p><img src="https://www.alexirpan.com/public/rl-hard/pendulum_results.png" alt="Graph of Pendulum results"/></p> <p>Algumas características de problemas nos quais aplicar DRL pode ser produtivo:</p> <ul> <li>é fácil gerar experiência em quantidades ilimitadas: quanto mais dados melhor, usar um simulador rápido</li> <li>é possível trabalhar num problema simplificado: ao invés de trabalhar no problema mais complexo possível (afinal, RL resolve tudo!), é melhor simplificá-lo e ver se o método resolve esse problema simplificado. E.g., trabalhar apenas em um cenário de muitos, com apenas um tipo de agente e espaço de ações limitado</li> <li>é possível utilizar <em>self-play</em>: em um cenário competitivo, permitir que o agente controle ambos os agentes e aprenda de si próprio. Funciona bem no AlphaZero, Dota 2 e Super Smash Bros.</li> <li>é fácil definir uma recompensa da qual o agente não possa se aproveitar: +1 por ganhar, -1 por perder. Nos papers de NAS, a recompensa é a acurácia da rede gerada no dataset de validação, ou seja, exatamente o que se deseja maximizar.</li> <li> <p>se a recompensa for modelada (<em>reward shaping</em>), tentar fazê-la ser rica: no ambiente que eu trabalhei durante o doutorado (SMAC), os agentes recebiam:</p> <ul> <li>uma recompensa proporcional à quantia de dano que inferiam no adversário, num determinado ataque</li> <li>uma recompensa maior por derrotar uma unidade adversária (<em>last hit</em>)</li> <li>uma recompensa maior ainda por derrotar todas as unidades adversárias (ganhar a partida)</li> </ul> <p>o autor também aponta que, quanto menor o intervalo entre uma ação e a recompensa associada àquela ação, mais fácil para o agente aprender.</p> </li> </ul>]]></content><author><name></name></author><category term="deep-reinforcement-learning"/><category term="português"/><summary type="html"><![CDATA[Essa é uma compilação de textos que eu encontrei na internet em momentos de frustração com meu trabalho. Eu os resumi e traduzi para compartilhar com as pessoas sempre que me perguntarem porque trabalhar com DRL é uma desgraça.]]></summary></entry><entry><title type="html">Classificação da base de dados Iris - redes menores e regularização</title><link href="https://douglasrizzo.github.io/blog/2020/08/regularizacao-microrede/" rel="alternate" type="text/html" title="Classificação da base de dados Iris - redes menores e regularização"/><published>2020-08-19T00:00:00+00:00</published><updated>2020-08-19T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2020/08/regularizacao-microrede</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2020/08/regularizacao-microrede/"><![CDATA[<p><a href="https://colab.research.google.com/drive/1kOaj4ogt13P0XlaoZ0wqezgEP9KCB8bf?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p> <p>Este notebook continua uma série na qual foram introduzidas a base de dados Iris e o método de treinamento e avaliação de redes neurais <a href="https://colab.research.google.com/drive/13r1TY_BF1AXOMH8ufDEct3E8g243sONM#scrollTo=MLs97GxwgNrs">[1]</a> e o PCA <a href="https://colab.research.google.com/drive/15vsVfH-qlJP2YBCdgS8V8uc8jjkRYCFs#scrollTo=LOpZfT9qCa3K">[2]</a>.</p> <p>No primeiro notebook, foram mencionadas duas coisas que serão testadas aqui.</p> <ol> <li>redes neurais maiores (com mais pesos treináveis) possuem maior predisposição ao <em>overfitting</em>.</li> <li>existe uma técnica, chamada <em>regularização</em>, capaz de combater o <em>overfitting</em>.</li> </ol> <p>Neste notebook, uma rede consideravelmente menor será treinada para classificar a base de dados Iris. Não só isso, como ela usará a primeira componente principal retornada pelo PCA, trabalhando tanto com menos pesos como menos dados.</p> <p>Além disso, treinaremos a rede neural original, utilizada nos notebooks anteriores, com regularização L2 e observaremos a ausência de <em>overfitting</em> quando a rede é treinada por longos períodos de tempo.</p> <h1 id="importando-pacotes-e-criando-funções">Importando pacotes e criando funções</h1> <p>As funções abaixo aplicam o PCA numa base de dados e avaliam uma rede neural, retornando as medidas para serem exibidas em gráficos posteriormente.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="n">tensorflow.keras</span> <span class="k">as</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="k">def</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
  <span class="n">pca</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
  <span class="n">new_X</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">iris_X</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Tamanho da base de dados antes: </span><span class="sh">'</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Tamanho da base de dados depois: </span><span class="sh">'</span><span class="p">,</span> <span class="n">new_X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Porcentagem da variância explicada por cada coluna:</span><span class="sh">'</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Variância acumulada nas colunas remanescentes:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">sum</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">new_X</span>

<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
  
  <span class="n">y_train_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
  <span class="n">y_test_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

  <span class="n">model</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="sh">'</span><span class="s">weights.hdf5</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
  <span class="n">y_pred_onehot</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>
  
  <span class="n">v1</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">v2</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">v3</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_categorical_accuracy</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">v4</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">]</span>

  <span class="n">model</span><span class="p">.</span><span class="nf">load_weights</span><span class="p">(</span><span class="sh">'</span><span class="s">weights.hdf5</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  
  <span class="n">v5</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">v6</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">]</span>
  
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
  <span class="n">y_pred_onehot</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v3</span><span class="p">,</span> <span class="n">v4</span><span class="p">,</span> <span class="n">v5</span><span class="p">,</span> <span class="n">v6</span>
</code></pre></div></div> <h2 id="preparando-os-dados">Preparando os dados</h2> <p>Usaremos o pacote <em>scikit-learn</em> para carregar a base de dados Iris. Vamos geraruma versão da base com o menor número possível de componentes principais (1).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">iris_X_tiny</span> <span class="o">=</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tamanho da base de dados antes:  (150, 4)
Tamanho da base de dados depois:  (150, 1)
Porcentagem da variância explicada por cada coluna: [0.92461872]
Variância acumulada nas colunas remanescentes: 0.9246187232017271
</code></pre></div></div> <h1 id="regularização">Regularização</h1> <p>Em termos matemáticos, o <em>overfitting</em> ocorre quando os pesos de uma rede neural assumem magnitudes (positivas ou negativas) muito altas, permitindo que as funções que essas redes neurais modelam se tornem demasiadamente complexas para a função de erro que tentam minimizar.</p> <p>Na imagem abaixo, ambas as funções azul e verde se ajustam aos dados vermelhos, porém a função azul assumiu uma forma desnecessariamente complexa. Caso um novo ponto vermelho seja adicionado, é possível que a função verde esteja mais próxima dele do que a função azul, indicando que a função verde generaliza melhor os dados observados, mesmo sendo mais simples.</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/0/02/Regularization.svg" alt="Regularização"/></p> <p>A diferença entre as duas funções está no fato da função verde ter sido regularizada. Em sua forma mais simples, a regularização é feita somando-se os pesos da rede neural à função de erro que a rede tenta minimizar. Imaginando que $L(\theta)$ é a função de erro que usamos até agora, $R(\theta)$ é o novo termo de regularização que incluímos.</p> <p>\[J(\theta)=L(\theta) + \lambda R(\theta)\]</p> <p>Uma regularização comumente usada é a L2, na qual somamos o quadrado dos pesos da rede neural à função de erro. Isso tem o efeito de punir demasiadamente pesos muito grandes, ignorando pesos pequenos. O termo $\lambda$ é um coeficiente que indica o quão relevante o termo de regularização é na fórmula total do erro. Ele será utilizado na declaração da rede neural que faremos em Keras.</p> <p>\[J(\theta)=L(\theta) + \lambda \sum_w^{\theta}w^2\]</p> <p>Com a regularização, a rede neural deve alcançar o menor erro possível com os menores pesos possíveis, evitando o <em>overfitting</em>.</p> <p>As funções abaixo vão criar as rede neurais.</p> <ol> <li>A primeira foi utilizada nos tutoriais anterior e possui 4 entradas, 4 camadas e 213 pesos treináveis.</li> <li>A segunda é igual à primeira, porém com a regularização configurada nas camadas.</li> <li>A última rede possui aproximadamente 10% do tamanho da primeira, 1 entrada, 3 camadas e 23 pesos treináveis.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_large_model</span><span class="p">(</span><span class="n">input_dim</span><span class="p">):</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">create_regularized_model</span><span class="p">(</span><span class="n">input_dim</span><span class="p">):</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span>  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span>  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">,</span>  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">create_tiny_model</span><span class="p">(</span><span class="n">input_dim</span><span class="p">):</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="n">large_net</span> <span class="o">=</span> <span class="nf">create_large_model</span><span class="p">(</span><span class="n">iris_X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">reg_net</span> <span class="o">=</span> <span class="nf">create_regularized_model</span><span class="p">(</span><span class="n">iris_X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">tiny_net</span> <span class="o">=</span> <span class="nf">create_tiny_model</span><span class="p">(</span><span class="n">iris_X_tiny</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">large_net</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
<span class="n">tiny_net</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 10)                50        
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 88        
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 54        
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 21        
=================================================================
Total params: 213
Trainable params: 213
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_8 (Dense)              (None, 3)                 6         
_________________________________________________________________
dense_9 (Dense)              (None, 2)                 8         
_________________________________________________________________
dense_10 (Dense)             (None, 3)                 9         
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div> <p>Vamos utilizar nossa função <code class="language-plaintext highlighter-rouge">evaluate_model()</code> para avaliar as redes. As redes maiorws serão treinadas na base original e a rede menor, na 1ª componente principal dessa base.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">acc1_large</span><span class="p">,</span> <span class="n">l1_large</span><span class="p">,</span> <span class="n">acc_v_large</span><span class="p">,</span> <span class="n">lv_large</span><span class="p">,</span> <span class="n">acc2_large</span><span class="p">,</span> <span class="n">l2_large</span> <span class="o">=</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">large_net</span><span class="p">,</span> <span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
<span class="n">acc1_reg</span><span class="p">,</span> <span class="n">l1_reg</span><span class="p">,</span> <span class="n">acc_v_reg</span><span class="p">,</span> <span class="n">lv_reg</span><span class="p">,</span> <span class="n">acc2_reg</span><span class="p">,</span> <span class="n">l2_reg</span> <span class="o">=</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">reg_net</span><span class="p">,</span> <span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
<span class="n">acc1_tiny</span><span class="p">,</span> <span class="n">l1_tiny</span><span class="p">,</span> <span class="n">acc_v_tiny</span><span class="p">,</span> <span class="n">lv_tiny</span><span class="p">,</span> <span class="n">acc2_tiny</span><span class="p">,</span> <span class="n">l2_tiny</span> <span class="o">=</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">tiny_net</span><span class="p">,</span> <span class="n">iris_X_tiny</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.75      1.00      0.86         6
           2       1.00      0.82      0.90        11

    accuracy                           0.93        30
   macro avg       0.92      0.94      0.92        30
weighted avg       0.95      0.93      0.93        30

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       1.00      0.83      0.91         6
           2       0.92      1.00      0.96        11

    accuracy                           0.97        30
   macro avg       0.97      0.94      0.96        30
weighted avg       0.97      0.97      0.97        30

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       1.00      0.83      0.91         6
           2       0.92      1.00      0.96        11

    accuracy                           0.97        30
   macro avg       0.97      0.94      0.96        30
weighted avg       0.97      0.97      0.97        30

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       1.00      0.83      0.91         6
           2       0.92      1.00      0.96        11

    accuracy                           0.97        30
   macro avg       0.97      0.94      0.96        30
weighted avg       0.97      0.97      0.97        30

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.67      1.00      0.80         6
           2       1.00      0.73      0.84        11

    accuracy                           0.90        30
   macro avg       0.89      0.91      0.88        30
weighted avg       0.93      0.90      0.90        30

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.83      0.83      0.83         6
           2       0.91      0.91      0.91        11

    accuracy                           0.93        30
   macro avg       0.91      0.91      0.91        30
weighted avg       0.93      0.93      0.93        30
</code></pre></div></div> <p>São exibidos os valores para cada rede treinada na base de treinamento por 2500 épocas e depois por 150 eṕocas. Espera-se que o desempenho das redes neurais que sofram de <em>overfitting</em> seja inferior nos valores impresso primeiro.</p> <p>Os valores podem mudar aleatoriamente, porém é possível perceber através dos valores de precisão, recall, F1-score e pela matriz de confusão que o desempenho de ambas as redes é comparável e, muitas vezes, idêntico.</p> <p>Vamos gerar gráficos das 6 medidas coletadas dos dois modelos.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc1_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc1_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc1_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Acurácia Treino</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l1_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l1_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l1_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Erro Treino</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc_v_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc_v_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc_v_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Acurácia Val.</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">lv_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">lv_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">lv_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Erro Val.</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc2_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc2_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">acc2_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Acurácia total</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l2_large</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l2_reg</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">l2_tiny</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Erro total</span><span class="sh">'</span><span class="p">)</span>

<span class="n">legenda</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Grande</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Regularizada</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Pequena</span><span class="sh">'</span><span class="p">]</span>
<span class="n">xlabel</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Épocas</span><span class="sh">'</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legenda</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="/assets/img/2020-08-19-regularizacao-microrede_output_11_0.png" alt="png"/></p> <p>Ambas as redes foram treinadas por 2500 épocas e avaliadas no conjunto de validação para constatar a presença de <em>overfitting</em> (4 primeiros gráficos). Depois, foram treinadas novamente por 150 épocas na totalidade dos dados de treinamento (2 últimos gráficos).</p> <p>O gráfico de erro no conjunto de treinamento (topo, direita) nos mostra que a rede menor leva mais épocas para aprender. Seu erro diminui lentamente. A rede regularizada não consegue diminuir seu erro tanto quanto as redes não regularizadas devido à restrição em seus pesos. Isso pode parecer ruim, mas veremos um efeito positivo da regularização a seguir.</p> <p>O gráfico de erro no conjunto de validação (centro, direita) demonstra que o erro da rede grande não-regularizada começa a crescer linearmente após aproximadamente 200 épocas. Um período de treinamento muito extenso apenas prejudica esta rede. A rede menor, apesar de ser menos afetada pelo <em>overfitting</em>, ainda demonstra aumenta do erro após muitas épocas de treinamento. Porém, este aumento é mais lento que na rede neural grande. Por último, a rede grande regularizada não demonstra aumento do erro no conjunto de validação, independente da quantidade de épocas de treinamento.</p> <p>Essa é uma característica interessante no mundo real, quando não sabemos exatamente a topologia exata da rede neural que solucionará nosso problema em questão, ou por quantas épocas de treinamento é necessário treinar o modelo.</p> <h1 id="conclusão">Conclusão</h1> <p>Este notebook demonstrou que uma rede neural consideravelmente menor que a utilizada até o momento é capaz de realizar a classificação das flores na base de dados Iris, utilizando 1/4 dos valores de entrada, 3/4 do número de camadas e aproximadamente 1/10 dos pesos treináveis.</p>]]></content><author><name></name></author><category term="colab"/><category term="portugues"/><category term="keras"/><category term="neural-networks"/><category term="python"/><category term="classification"/><category term="tutorial"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Classificação da base de dados Iris utilizando redes neurais e PCA</title><link href="https://douglasrizzo.github.io/blog/2020/08/iris-pca-keras/" rel="alternate" type="text/html" title="Classificação da base de dados Iris utilizando redes neurais e PCA"/><published>2020-08-16T00:00:00+00:00</published><updated>2020-08-16T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2020/08/iris-pca-keras</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2020/08/iris-pca-keras/"><![CDATA[<p><a href="https://colab.research.google.com/drive/15vsVfH-qlJP2YBCdgS8V8uc8jjkRYCFs?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p> <p>Este notebook exemplifica a redução de dimensionalidades de uma base de dados e a posterior classificação de seus itens utilizando uma rede neural. A redução de dimensionalidades é executada utilizando <a href="https://pt.wikipedia.org/wiki/An%C3%A1lise_de_componentes_principais">análise de componentes principais</a>, disponível no pacote <em>scikit-learn</em> e a rede neural é um perceptron multi-camadas, construído utilizando Keras.</p> <p>Este notebook é uma continuação de um outro no qual a base de dados utilizada (Iris) e o método de treinamento e avaliação da rede neural já foram descritos. O notebook anterior está disponível <a href="https://colab.research.google.com/drive/13r1TY_BF1AXOMH8ufDEct3E8g243sONM#scrollTo=MLs97GxwgNrs">aqui</a>.</p> <h1 id="importando-pacotes-e-criando-funções">Importando pacotes e criando funções</h1> <p>Vamos utilizar scikit-learn e Keras. Também vamos criar algumas funções para simplificar o treinamento e avaliar de uma rede neural, que já foram descritos no notebook anterior.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="n">tensorflow.keras</span> <span class="k">as</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">input_dim</span><span class="p">):</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

  <span class="c1">#  "Accuracy"
</span>  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Acurácia</span><span class="sh">'</span><span class="p">)</span>
  <span class="c1"># "Loss"
</span>  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">])</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Erro</span><span class="sh">'</span><span class="p">)</span>

  <span class="k">if</span> <span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Treino</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Validação</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Treino</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Validação</span><span class="sh">'</span><span class="p">])</span>

  <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Épocas</span><span class="sh">'</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">do_everything</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
  
  <span class="n">y_train_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
  <span class="n">y_test_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

  <span class="n">model</span><span class="o">=</span><span class="nf">create_model</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">())</span>

  <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>

  <span class="n">model</span><span class="o">=</span><span class="nf">create_model</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>

  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
  <span class="n">y_pred_onehot</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>
</code></pre></div></div> <h1 id="análise-de-componentes-principais">Análise de componentes principais</h1> <p>A análise de componentes principais (PCA, do inglês <em>principal component analysis</em>) é uma técnica matemática que detecta correlações nas colunas de uma matriz $X$ e realiza uma transformação linear em $X$ de forma a reduzir tais correlações.</p> <p>Em linhas gerais, dados altamente correlacionadas são pouco informativos, inclusive para o treinamento de um classificador. Considere uma base de dados hipotética de cidades que possui as seguintes informações para cada cidade:</p> <ol> <li>distância do Equador em quilômetros</li> <li>distância do Equador em léguas</li> <li>temperatura em °C</li> <li>temperatura em °F</li> </ol> <p>É possível perceber que os dados 1 e 2 são redundantes, por armazenarem a mesma informação, apenas em escalas diferentes, assim como os dados 3 e 4. Não só isso, como a temperatura de uma cidade é altamente correlacionada com sua distância do Equador. Uma técnica como o PCA encontraria as correlações nesta matriz de 4 colunas e transformaria as colunas de forma a reduzir (ou zerar) tais correlações.</p> <p>Esta transformação pode ter como efeito colateral a concentração da informação das colunas na matriz original em menos colunas na matriz transformada. Por consequência, seria possível <strong>remover as colunas menos informativas</strong>, reduzindo a complexidade dos dados, mas retendo a informação necessária para se treinar um classificador, por exemplo.</p> <p>A redução de dimensionalidade de dados proveniente do PCA também é útil para fins de visualização de dados multidimensionais.</p> <h2 id="preparando-os-dados">Preparando os dados</h2> <p>Usaremos o pacote <em>scikit-learn</em> para carregar a base de dados Iris. Repare que ela possui 150 flores e 4 características por flor. No notebook anterior, utilizamos todas as 4 características para treinar nossa rede neural. Neste notebook, tentaremos realizar a mesma classificação com um menor número de características.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Qtd. itens no conj. de treinamento:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">iris_X</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Classes:</span><span class="sh">'</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">Exemplos das medidas de 5 flores:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">iris_X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Qtd. itens no conj. de treinamento: 150
Classes: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]

Exemplos das medidas de 5 flores:
[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]]
</code></pre></div></div> <h1 id="aplicando-o-pca-na-base-de-dados-iris">Aplicando o PCA na base de dados Iris</h1> <p>O PCA está implementado no <em>scikit-learn</em> e pode ser aplicado como no exemplo abaixo. Vamos criar uma função que aplica o PCA a um conjunto de dados, exibe informações de sua aplicação e retorna o conjuntos de dados transformados.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
  <span class="n">pca</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
  <span class="n">new_X</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">iris_X</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Tamanho da base de dados antes: </span><span class="sh">'</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Tamanho da base de dados depois: </span><span class="sh">'</span><span class="p">,</span> <span class="n">new_X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Porcentagem da variância explicada por cada coluna:</span><span class="sh">'</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Variância acumulada nas colunas remanescentes:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">sum</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">new_X</span>
</code></pre></div></div> <p>Vamos aplicar o PCA nas medidas de nossas flores e observar a remoção da correlação das colunas e concentração das informações em menos colunas.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X_4cp</span> <span class="o">=</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tamanho da base de dados antes:  (150, 4)
Tamanho da base de dados depois:  (150, 4)
Porcentagem da variância explicada por cada coluna: [0.92461872 0.05306648 0.01710261 0.00521218]
Variância acumulada nas colunas remanescentes: 1.0
</code></pre></div></div> <p>Perceba como nossa base dados ainda possui o mesmo número de características (4). Porém, 92% da informação das colunas originais (representada pela variância) está agora concentrada na primeira coluna. Isso é um forte indicativo de que podemos classificar nossos dados utilizando menos características.</p> <p>O PCA costuma ordenar as colunas da nova base de dados em ordem decrescente de quantidade de informação, então, para garantir que estamos utilizando as colunas mais informativas de nossa base, basta ignorarmos as últimas colunas da matriz.</p> <h1 id="aplicando-o-pca-para-3-componentes">Aplicando o PCA para 3 componentes</h1> <p>Agora vamos aplicar o PCA e remover a coluna menos informativa. Isso tem o mesmo efeito de utilizar as 3 primeiras colunas da matriz gerada anteriormente, mas vamos aplicar o método de novo de qualquer forma.</p> <p>Repare como as colunas remanescentes ainda mantêm 99,4% da informação da base de dados original.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X_3cp</span> <span class="o">=</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tamanho da base de dados antes:  (150, 4)
Tamanho da base de dados depois:  (150, 3)
Porcentagem da variância explicada por cada coluna: [0.92461872 0.05306648 0.01710261]
Variância acumulada nas colunas remanescentes: 0.9947878161267247
</code></pre></div></div> <p>Vamos utilizar nossas funções de treinamento e avaliação de redes neurais para treinar um modelo nos dados reduzidos.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">do_everything</span><span class="p">(</span><span class="n">iris_X_3cp</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 10)                40        
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 88        
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 54        
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 21        
=================================================================
Total params: 203
Trainable params: 203
Non-trainable params: 0
_________________________________________________________________
None
</code></pre></div></div> <p><img src="/assets/img/output_14_1.png" alt="png"/></p> <p><img src="/assets/img/output_14_2.png" alt="png"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       1.00      1.00      1.00         6
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30

[[13  0  0]
 [ 0  6  0]
 [ 0  0 11]]
</code></pre></div></div> <p>É possível observar que a rede neural é treinada com sucesso utilizando apenas as 3 características mais informativas provenientes do PCA. A rede ainda alcança altos valores de precisão, revocação e F1-score. Também é possível perceber que, assim como no notebook anterior, o <em>overfitting</em> ainda ocorre caso treinemos a rede neural por épocas demais. Isso, o PCA não resolve.</p> <h1 id="aplicando-o-pca-para-2-componentes">Aplicando o PCA para 2 componentes</h1> <p>Vamos reduzir nossa base de dados mais ainda, mantendo apenas 2 colunas.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X_2cp</span> <span class="o">=</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tamanho da base de dados antes:  (150, 4)
Tamanho da base de dados depois:  (150, 2)
Porcentagem da variância explicada por cada coluna: [0.92461872 0.05306648]
Variância acumulada nas colunas remanescentes: 0.977685206318795
</code></pre></div></div> <p>Mesmo mantendo metade das colunas originais, ainda retemos 97,7% da informação de nossas flores. Vamos treinar nosso classificador usando esta nova base.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">do_everything</span><span class="p">(</span><span class="n">iris_X_2cp</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_8 (Dense)              (None, 10)                30        
_________________________________________________________________
dense_9 (Dense)              (None, 8)                 88        
_________________________________________________________________
dense_10 (Dense)             (None, 6)                 54        
_________________________________________________________________
dense_11 (Dense)             (None, 3)                 21        
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
</code></pre></div></div> <p><img src="/assets/img/output_19_1.png" alt="png"/></p> <p><img src="/assets/img/output_19_2.png" alt="png"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.83      0.83      0.83         6
           2       0.91      0.91      0.91        11

    accuracy                           0.93        30
   macro avg       0.91      0.91      0.91        30
weighted avg       0.93      0.93      0.93        30

[[13  0  0]
 [ 0  5  1]
 [ 0  1 10]]
</code></pre></div></div> <p>Novamente, a rede neural ainda classifica os dados com sucesso, porém pode começar a demonstrar perda de desempenho, como demonstrado por valores de precisão, revocação e F1-score menores ou uma matriz de confusão com valores fora da diagonal principal.</p> <p>Outra informação muito interessante de ser reparada é a redução no número de pesos treináveis da rede, exibido no resumo da rede neural no início da célula anterior (<code class="language-plaintext highlighter-rouge">Trainable params</code>). A rede neural treinada para classificar os dados originais (com 4 características) precisa aprender mais pesos (213) do que uma rede que classifica dados com menos características (2 características, 193 pesos). Isso significa que, ao utilizar o PCA, uma rede neural menor que processa menos dados pode potencialmente ter o mesmo desempenho que uma rede maior que processa mais dados.</p> <h1 id="e-finalmente">E, finalmente…</h1> <p>Vamos treinar a rede para classificar nossa flores <strong>utilizando apenas 1 característica</strong>. A base de dados mantém 92,4% da informação, a rede neural possui 10 pesos a menos e ainda alcança um desempenho satisfatório.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X_1cp</span> <span class="o">=</span> <span class="nf">apply_PCA</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nf">do_everything</span><span class="p">(</span><span class="n">iris_X_1cp</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tamanho da base de dados antes:  (150, 4)
Tamanho da base de dados depois:  (150, 1)
Porcentagem da variância explicada por cada coluna: [0.92461872]
Variância acumulada nas colunas remanescentes: 0.9246187232017271
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 10)                20        
_________________________________________________________________
dense_17 (Dense)             (None, 8)                 88        
_________________________________________________________________
dense_18 (Dense)             (None, 6)                 54        
_________________________________________________________________
dense_19 (Dense)             (None, 3)                 21        
=================================================================
Total params: 183
Trainable params: 183
Non-trainable params: 0
_________________________________________________________________
None
</code></pre></div></div> <p><img src="/assets/img/output_22_1.png" alt="png"/></p> <p><img src="/assets/img/output_22_2.png" alt="png"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.67      1.00      0.80         6
           2       1.00      0.73      0.84        11

    accuracy                           0.90        30
   macro avg       0.89      0.91      0.88        30
weighted avg       0.93      0.90      0.90        30

[[13  0  0]
 [ 0  6  0]
 [ 0  3  8]]
</code></pre></div></div> <h1 id="conclusão">Conclusão</h1> <p>Este notebook explicou o PCA, uma técnica que transforma uma base de dados, representada por uma matriz, em uma nova matriz cujas colunas possuem menos correlação e maior concentração de informação em um menor número ce colunas.</p> <p>O PCA foi exemplificado na base de dados Iris e redes neurais foram treinadas para classificar as flores utilizando cada vez menos características.</p>]]></content><author><name></name></author><category term="colab"/><category term="portugues"/><category term="keras"/><category term="neural-networks"/><category term="python"/><category term="classification"/><category term="tutorial"/><category term="pca"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Classificação da base de dados Iris utilizando um perceptron multi-camadas em Keras</title><link href="https://douglasrizzo.github.io/blog/2020/08/iris-keras/" rel="alternate" type="text/html" title="Classificação da base de dados Iris utilizando um perceptron multi-camadas em Keras"/><published>2020-08-14T00:00:00+00:00</published><updated>2020-08-14T00:00:00+00:00</updated><id>https://douglasrizzo.github.io/blog/2020/08/iris-keras</id><content type="html" xml:base="https://douglasrizzo.github.io/blog/2020/08/iris-keras/"><![CDATA[<p><a href="https://colab.research.google.com/drive/13r1TY_BF1AXOMH8ufDEct3E8g243sONM?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p> <p>Este notebook exemplifica o treinamento de uma perceptron multi-camadas na classificação da base de dados Iris. O notebook utiliza o pacote <em>scikit-learn</em> para carregamento e separação da base de dados em treinamento e teste, o pacote <em>keras</em> para criação e treinamento da rede neural e o <em>matplotlib</em> para a geração de gráficos.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="n">tensorflow.keras</span> <span class="k">as</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
</code></pre></div></div> <h1 id="sobre-a-base-de-dados">Sobre a base de dados</h1> <p>A base de dados Iris contém 4 medidas de 150 flores individuais de 3 espécies distintas (50 flores de cada espécie). Ela foi criada em 1936 por Ronald Fisher <a href="https://pt.wikipedia.org/wiki/Conjunto_de_dados_flor_Iris">[link]</a>.</p> <p>As medidas são a altura e larguras das <a href="https://pt.wikipedia.org/wiki/P%C3%A9tala">pétalas</a> e <a href="https://pt.wikipedia.org/wiki/S%C3%A9pala">sépalas</a> de cada flor e as espécies de flores são <em>iris setosa</em>, <em>iris versicolor</em> e <em>iris virginica</em>, apresentadas nas imagens abaixo.</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg" alt="Iris setosa"/> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg" alt="Iris versicolor"/> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg" alt="Iris virginica"/></p> <h2 id="visualizando-a-iris">Visualizando a Iris</h2> <p>Apenas momentaneamente, utilizaremos o pacote <em>seaborn</em> para exibir as características das flores e suas espécies em um gráfico. Os pontos significam flores individuais, as cores simbolizam as espécies às quais cada flor pertence e linhas/colunas exibem pares de características <em>plotados</em> uns contra os outros.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">iris</span><span class="sh">"</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">pairplot</span><span class="p">(</span><span class="n">iris</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="sh">"</span><span class="s">species</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="/assets/img/output_3_1.png" alt="png"/></p> <p>Para a tarefa de classificação, a rede neural deve conseguir diferenciar entre as 3 espécies de flores, dadas suas medidas. É possível perceber visualmente que esta é uma tarefa fácil.</p> <p>Por exemplo, todas as flores da espécie <em>iris setosa</em> (em azul) possuem altura e largura de pétala (<code class="language-plaintext highlighter-rouge">petal_length</code> e <code class="language-plaintext highlighter-rouge">petal_width</code>) menores do que qualquer flor de qualquer outra espécie. Uma rede neural que conseguisse aprender que toda flor da espécie <em>iris setosa</em> possui <code class="language-plaintext highlighter-rouge">petal_length &lt; 2</code> ou <code class="language-plaintext highlighter-rouge">petal_width &lt; 0.8</code> conseguiria classificar esta classe com 100% de precisão.</p> <p>Tudo o que uma rede neural faz durante o aprendizado é descobrir pontos de separação entre as classes, como o exemplificado acima, utilizando características (ou combinações de características) presentes na base de dados.</p> <h2 id="preparando-os-dados">Preparando os dados</h2> <p>Usaremos o pacote <em>scikit-learn</em> para carregar a base de dados e visualizar suas informações. As medidas das flores e suas respectivas classes são carregadas em variáveis distintas.</p> <p>Repare que a base possui 150 flores, que as classes são representadas pelos números inteiros 0, 1 e 2 e as características das flores são armazenadas em uma única matriz de 150 linhas (as flores) por 4 colunas (as medidas).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Qtd. itens no conj. de treinamento:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">iris_X</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Classes:</span><span class="sh">'</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">Exemplos de medida de 5 flores:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">iris_X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Qtd. itens no conj. de treinamento: 150
Classes: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]

Exemplos de medida de 5 flores:
[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]]
</code></pre></div></div> <p>Vamos separar nossa base de dados em conjuntos de treinamento e de teste. O conjunto de treinamento será utilizado para treinar o modelo criado e o conjunto de testes, utilizado na avaliação do modelo após o treinamento.</p> <p>O desempenho da rede neural no conjunto de treinamento é um indicativo da <strong>capacidade de aprendizado</strong> do modelo, enquanto o desempenho no conjunto de testes indica a <strong>capacidade de generalização</strong> da rede, ou seja, sua capacidade de classificar novos dados (nunca antes vistos) corretamente.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">iris_X</span><span class="p">,</span>
                                                    <span class="n">iris_y</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Qtd. itens no conj. de treinamento:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Qtd. itens no conj. de teste:</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Qtd. itens no conj. de treinamento: 120

Qtd. itens no conj. de teste: 30
</code></pre></div></div> <h2 id="one-hot-encoding">One-hot encoding</h2> <p>A forma como as classes são representadas atualmente (0, 1 e 2) não é a melhor para que a rede aprenda a tarefa de classificação. Isso porque, caso a rede tenha apenas uma saída (um número entre 0 e 2), ao aprender a realizar a saída 2, a rede pode aos poucos “desaprender” a saída 0, por serem valores de classes opostos.</p> <p>Uma forma de mitigar este problema é fazer com que o aprendizado de cada classe seja independente do aprendizado de todas as outras. Se a rede tiver 3 saídas e aprendar a maximizar o valor de uma saída independente das outras, podemos escolher o maior valor dos três como a classificação correta.</p> <p>Para isso, modificaremos a representação de nossas classes utilizando utilizando <a href="https://en.wikipedia.org/wiki/One-hot"><em>one-hot encoding</em></a>, uma espécie de categorização de dados que torna o aprendizado de classe linearmente independente para a rede neural.</p> <p>Perceba como os números 0, 1 e 2 se tornam as sequências 100, 010 e 001, respectivamente.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">y_test_onehot</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># imprime os 5 primeiros valores para exemplificar
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">### Antes ###</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">### Depois ###</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_train_onehot</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_test_onehot</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Antes ###
[2 2 0 0 1]
[1 2 2 1 0]

### Depois ###
[[0. 0. 1.]
 [0. 0. 1.]
 [1. 0. 0.]
 [1. 0. 0.]
 [0. 1. 0.]]
[[0. 1. 0.]
 [0. 0. 1.]
 [0. 0. 1.]
 [0. 1. 0.]
 [1. 0. 0.]]
</code></pre></div></div> <h1 id="declarando-a-topologia-da-rede-neural">Declarando a topologia da rede neural</h1> <p>Neste notebook, uma rede neural será utilizada para descobrir a qual das 3 espécies cada flor pertence, dadas suas 4 medidas. Em outras palavras, a rede neural será um classificador treinado para prever em qual classe (de 3) um vetor de 4 valores pertence.</p> <p>Vamos construir uma rede neural utilizando Keras. Aqui, configuramos camadas, neurônios por camada, funções de ativação, otimizador e função de erro.</p> <p>Após construir a rede neural, utilizamos uma função utilitária do Keras para exibir a topologia do modelo. Neste caso, a rede receberá como entrada vetores de tamanho 4 (correspondente à quantidade de medidas de nossas pétalas e utilizará 4 camadas densas para realizar a classificação.</p> <p>Repare que o tamanho da entrada de uma camada equivale ao tamanho da saída da camada anterior, permitindo que camadas sejam encadeadas para aumentar a expressividade da rede.</p> <p>A última camada da rede tem como saída vetores de tamanho 3, correspondentes à quantidade de espécies de flores que desejamos classificar.</p> <p>Vamos criar uma função para conseguir recriar o mesmo modelo no futuro.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span><span class="o">=</span><span class="nf">create_model</span><span class="p">()</span>

<span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">plot_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">show_shapes</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">show_layer_names</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">rankdir</span><span class="o">=</span><span class="sh">"</span><span class="s">LR</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">expand_nested</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">dpi</span><span class="o">=</span><span class="mi">96</span>
<span class="p">)</span>
</code></pre></div></div> <p><img src="/assets/img/output_12_0.png" alt="png"/></p> <p>Como uma biblioteca de redes neurais de alto nível, o Keras abstrai algumas complexidades da configuração do método de treinamento. Existem diferentes opções de otimizadores e funções de erro que podem ser utilizadas com a biblioteca, que podem ter diferentes efeitos no tempo de treinamento da rede. Opções comuns de otimizadores incluem <code class="language-plaintext highlighter-rouge">sgd</code> , <code class="language-plaintext highlighter-rouge">rmsprop</code> e <code class="language-plaintext highlighter-rouge">adam</code> . Já a função de erro <code class="language-plaintext highlighter-rouge">categorical_crossentropy</code> é a mais apropriada para tarefas de classificação multi-classes, quando as classes são representadas em <em>one-hot encoding</em>.</p> <h1 id="treinando-a-rede">Treinando a rede</h1> <p>Vamos treinar nossa rede neural. Ela aprenderá a realizar a classificação dos dados de treinamento ( <code class="language-plaintext highlighter-rouge">X_train</code> ) para as classes categorizadas ( <code class="language-plaintext highlighter-rouge">y_train_onehot</code> ) por um número de épocas pré-determinado.</p> <p>Durante o treinamento, o Keras armazena os valores da função de erro e outras medidas e permite acessá-los em uma variável, aqui chamada <code class="language-plaintext highlighter-rouge">history</code> .</p> <p>É possível executar a célula abaixo repetidas vezes para que a mesma rede seja treinada por mais épocas.</p> <p>Também é possível separar uma parcela do conjunto de treinamento para <em>validação</em>, a avaliação em tempo real da rede neural em um conjunto de dados que não é utilizado para treinamento.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/500
4/4 - 0s - loss: 1.3739 - categorical_accuracy: 0.0556 - val_loss: 1.5228 - val_categorical_accuracy: 0.0000e+00
Epoch 2/500
4/4 - 0s - loss: 1.3304 - categorical_accuracy: 0.0093 - val_loss: 1.4575 - val_categorical_accuracy: 0.0000e+00

[...]

Epoch 499/500
4/4 - 0s - loss: 0.0104 - categorical_accuracy: 1.0000 - val_loss: 0.3896 - val_categorical_accuracy: 0.9167
Epoch 500/500
4/4 - 0s - loss: 0.0099 - categorical_accuracy: 1.0000 - val_loss: 0.3817 - val_categorical_accuracy: 0.9167
</code></pre></div></div> <p>Vamos criar um gráfico com o erro e a acurácia da rede ao longo das épocas de treinamento. Caso uma parcela do conjunto de treinamento tenha sido utilizada para validação, novas linhas no gráfico exibirão o desempenho da rede neste conjunto separado de dados.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

  <span class="c1">#  "Accuracy"
</span>  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Acurácia</span><span class="sh">'</span><span class="p">)</span>
  <span class="c1"># "Loss"
</span>  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">])</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Erro</span><span class="sh">'</span><span class="p">)</span>

  <span class="k">if</span> <span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_categorical_accuracy</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Treino</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Validação</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Treino</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Validação</span><span class="sh">'</span><span class="p">])</span>

  <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Épocas</span><span class="sh">'</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</code></pre></div></div> <p><img src="/assets/img/output_17_0.png" alt="png"/></p> <h2 id="overfitting">Overfitting</h2> <p>O treino da rede neural por muitas épocas no conjunto de treinamento pode fazer com que o modelo se especialize neste conjunto de dados, um fenômeno chamado <a href="https://pt.wikipedia.org/wiki/Sobreajuste"><em>overfitting</em></a>.</p> <p>Essa especialização prejudica o desempenho da rede neural, uma vez que, ao se especializar, ela falha em generalizar sua capacidade de classificação para dados não observados.</p> <p>O <em>overfitting</em> pode ser visualizado quando o erro de classificação no conjunto de treinamento continua a diminuir, ao mesmo tempo em que o erro no conjunto de validação começa a aumentar. Este ponto pode ser considerado um bom momento para encerrar o treinamento da rede neural.</p> <p>Quando uma rede neural possui pesos demais para a tarefa que irá realizar, ela pode sofrer de <em>overfitting</em> se treinada por muitas épocas, ajustando-se demais aos dados de treinamento.</p> <p>Algumas formas de evitar o <em>overfitting</em> incluem:</p> <ul> <li>utilizar uma rede neural menor;</li> <li>utilizar regularização (que não será abordada aqui);</li> <li>parar o treinamento antes que o <em>overfitting</em> ocorra.</li> </ul> <p>Considerando as observações no primeiro treinamento da rede neural, vamos treiná-la novamente, dessa vez encerrando o treinamento mais cedo e evitando o <em>overfitting</em>. Adicionalmente, vamos utilizar o conjunto de treinamento em sua totalidade nesta rodada de treinamento, sem validação.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nf">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_onehot</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</code></pre></div></div> <p><img src="/assets/img/output_19_0.png" alt="png"/></p> <h1 id="realizando-inferências-com-o-modelo-treinado">Realizando inferências com o modelo treinado</h1> <p>Vamos utilizar a rede treinada para classificar os dados de teste que separamos no início e visualizar as classes preditas pelo modelo. A rede neural classifica todo o conjunto de testes de uma vez.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[0.01593729 0.60561794 0.37844476]
 [0.00296563 0.07939946 0.9176349 ]
 [0.00180538 0.04658297 0.95161164]
 [0.03136854 0.9468003  0.0218312 ]
 [0.962343   0.03639156 0.00126548]
 [0.01097725 0.33443207 0.65459067]
 [0.02357773 0.9411847  0.03523754]
 [0.96158886 0.0371284  0.00128271]
 [0.95949054 0.0391942  0.00131528]
 [0.02218457 0.8818209  0.09599455]
 [0.00703657 0.19524635 0.7977171 ]
 [0.9629769  0.03576834 0.00125479]
 [0.0274128  0.92334604 0.04924115]
 [0.00359261 0.09982508 0.8965823 ]
 [0.0021769  0.05739778 0.94042534]
 [0.00176867 0.04559813 0.9526332 ]
 [0.9619265  0.0368052  0.00126826]
 [0.9620646  0.03666212 0.00127322]
 [0.02267583 0.88068783 0.0966363 ]
 [0.9593102  0.0393738  0.00131598]
 [0.9614102  0.03731174 0.00127805]
 [0.01361755 0.4841447  0.50223774]
 [0.9575784  0.04107764 0.0013439 ]
 [0.00956561 0.2892796  0.70115477]
 [0.96190244 0.03682484 0.00127265]
 [0.9592192  0.03946826 0.00131252]
 [0.96002924 0.03866893 0.0013018 ]
 [0.00265293 0.06909027 0.92825687]
 [0.00196587 0.05123645 0.9467976 ]
 [0.96210897 0.03662174 0.00126931]]
</code></pre></div></div> <p>A saída da rede é um conjunto de 3 valores para cada vetor de entrada. Cada um dos 3 valores indica a relevância da respectiva classe para o vetor de entrada. Quanto maior essa relevância, maiores as chances do dado de entrada pertencer àquela classe.</p> <p>A função de ativação na última camada da rede neural dita a natureza dos valores de saída:</p> <ul> <li><code class="language-plaintext highlighter-rouge">tanh</code> : tangente hiperbólica (intervalo $[-1; 1]$).</li> <li><code class="language-plaintext highlighter-rouge">sigmoid</code> : sigmoide (intervalo $[0; 1]$).</li> <li><code class="language-plaintext highlighter-rouge">softmax</code> : <em>softmax</em> (intervalo $[0; 1]$, a soma dos valores preditos para cada dado de entrada deve ser igual a 1).</li> </ul> <p>Para transformar os valores exibidos acima nas classes preditas, escolhemos a maior saída no eixo das classes.</p> <p>Compare os valores verdadeiros com os valores preditos pela rede.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred_onehot</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Classes reais:</span><span class="se">\t\t</span><span class="sh">'</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Classes preditas:</span><span class="se">\t</span><span class="sh">'</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classes reais:		 [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]
Classes preditas:	 [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]
</code></pre></div></div> <h1 id="avaliando-a-rede-treinada">Avaliando a rede treinada</h1> <p>Utilizamos o <em>scikit-learn</em> para produzir relatórios de classificação utilizando os valores reais e os preditos.</p> <p>As medidas de desempenho da rede são precisão, <em>recall</em> (revocação) e F1 <a href="https://pt.wikipedia.org/wiki/Precis%C3%A3o_e_revoca%C3%A7%C3%A3o#Defini%C3%A7%C3%A3o_(contexto_de_classifica%C3%A7%C3%A3o)">[link]</a>.</p> <p>A precisão indica a quantidade de classificações positivas que a rede realizou que são realmente positivas. A revocação indica a fração de classificações positivas que a rede realizou, do total de classificações positivas.</p> <p>Em nosso contexto, podemos imaginar que essas medidas respondem às seguintes perguntas:</p> <ul> <li> <p><strong>Precisão:</strong> De todas as flores que meu classificador indicou como sendo da classe <em>iris setosa</em>, quais realmente são dessa classe?</p> </li> <li> <p><strong>Revocação:</strong> De todas as flores da espécie <em>iris setosa</em> presentes na minha base de dados, quantas o meu classificador conseguiu identificar?</p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       1.00      1.00      1.00         6
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30
</code></pre></div></div> <h2 id="detalhando-precisão-e-revocação">Detalhando precisão e revocação</h2> <p>A precisão e a revocação são valores relevantes sobre um modelo, porém suas definições podem ser um pouco confusas. Uma forma um pouco mais informativa de se pensar nestas medidas é utilizando-as na análise da eficácia de um teste médico hipotético (que toma o lugar de nosso modelo classificador) para uma doença e quais questões cada uma das medidas responde:</p> <ul> <li> <p><strong>Precisão:</strong> De todos os testes positivos realizados, quantos pacientes realmente possuem a doença?</p> </li> <li> <p><strong>Revocação:</strong> De todos os pacientes que realmente possuem a doença, qual a porcentagem que eu consegui identificar utilizando meu teste?</p> </li> </ul> <p>Caso o teste médico possua alta precisão, temos certeza que todos os pacientes que informarmos como portadores da doença, certamente terão a doença. Ou seja, o teste não estará errado nas classificações positivas que realiza.</p> <p>Caso o teste possua alta revocação, temos certeza que todos os portadores da doença em nossa população foram identificados.</p> <p>Porém, algumas situações anômalas podem surgir. Por exemplo, se há 1000 doentes em nossa amostra e nosso classificador realiza apenas 1 classificação positiva e o paciente está realmente doente, a precisão do modelo é de 100%, pois não fez nenhuma classificação positiva errada.</p> <p>Igualmente, se há 1000 doentes numa população de 1 milhão de pessoas e nosso classificador realiza 1 milhão de classificações positivas, ele possuirá uma revocação de 100%, uma vez que detectou todos os doentes.</p> <p>Devido a estas anomalias, é sempre preciso ponderar qual medida é mais importante para um classificador em uma determinada tarefa ou, na melhor das hipóteses, treinar um classificador que maximize ambas as medidas.</p> <p>A medida F-score (ou F-measure ou F1), também exibida acima, é uma combinação da precisão e da revocação e pode auxiliar na avaliação do classificador.</p> <h1 id="matriz-de-confusão">Matriz de confusão</h1> <p>A matriz de confusão compara, em números absolutos, as classes reais e preditas. Valores na diagonal principal indicam classificações corretas e qualquer outro valor indica erros de classificação no conjunto de testes.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_onehot</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[13  0  0]
 [ 0  6  0]
 [ 0  0 11]]
</code></pre></div></div> <h1 id="conclusão">Conclusão</h1> <p>Este <em>colab</em> apresentou um exemplo clássico e básico de classificação de uma base de dados utilizando redes neurais. Os seguintes conceitos foram apresentados ao longo do <em>colab</em>:</p> <ol> <li>apresentação da <strong>base de dados Iris</strong>, uma base muito famosa na área de estatística e aprendizado de máquina;</li> <li>separação da base de dados entre conjuntos de <strong>treinamento, validação e testes</strong>;</li> <li>criação de uma rede neural do tipo <strong>perceptron multi-camadas</strong> utilizando Keras;</li> <li><strong>treinamento da rede neural</strong> no conjunto de treinamento;</li> <li>observação e descrição do fenômeno de <strong><em>overfitting</em></strong> no conjunto de validação;</li> <li><strong>re-treinamento da rede neural</strong> de forma a prevenir o <em>overfitting</em>;</li> <li><strong>realização de inferenças</strong> em dados nunca obervados antes pela rede neural (o conjunto de testes);</li> <li>avaliação da rede neural utilizando <strong>precisão, revocação, F1-score e a matriz de confusão</strong>.</li> </ol>]]></content><author><name></name></author><category term="colab"/><category term="portugues"/><category term="keras"/><category term="neural-networks"/><category term="python"/><category term="classification"/><category term="tutorial"/><summary type="html"><![CDATA[]]></summary></entry></feed>